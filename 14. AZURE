6th OCT
========

portal.azure.com/#home


Cloud Deployments Models:
================================
Public Cloud:
--------------

Public Cloud: Now the entire IT industry is moving and migrating their applications to Public cloud, 
we are having many cloud vendors (ex; Microsoft Azure, AWS, GCP, Oracle cloud, Salesforce, IBM…etc.) 
these cloud providers are offering their cloud computing platform with public cloud concept, till now
the entire IT industry, the organizations/IT firms were having their own cloud (private cloud) and now 
the public cloud is available for all. Public cloud means the platform is available and accessible for all,
not our resources/services & data. We have to create an account/subscription in the vendors platform and then
will get an identity & with authentication/authorization process will happen to login 
to our subscription in the cloud platform then it will allow us to create the resources/services which all 
we need as per our application and project requirements.


ex- aws,azure gcp, saleforce
ex- gmail, outlook

Private Cloud:
--------------
Private Cloud/On-prem: Till now the entire IT industry(from decades), 
the IT firms/Organizations were having their own cloud and that is called a private cloud,
the IT firms were maintaining these infrastructure/Datacenters on their own expenses and responsibilities 
and this was accessible only for them. And they are responsible and accountable if some misshaped/disaster 
happened that is either natural disaster or manmade disaster have occurred.


-infrascture/datcenters
 VM's
 Networks
 Databases
 NSG's
 Loadbalancers
 TMP,
 Appservices,
 AKS
 Container services etc

Hybrid Cloud:
---------------
Hybrid Cloud: It is a combination of Public and Private cloud. (Ex : 
let us say our frontend application servers are hosted in cloud as public and DB servers
are in on-prem, now using VPN will connect from our back end server(i.e.. On-prem) to front 
end server(ie. On cloud) this type of Setup/Scenarios is called Hybrid cloud)

-combination of public and private cloud



Advantages of Cloud Computing:
1)24/7 availability & accessibility: It is available & accessible from anywhere & at any time we only need to have device and internet connectivity to access the Azure resources/services.
2)Scalability: The face of transformation is very simple and ease in cloud computing (ex; resizing of resources/workloads/services…etc.) and that can be done just with click of a mouse.
3)Security: it is using a very high security algorithms and Hash functions to protect our data & resources.
4)Enhanced collaboration: Just in one platform(portal.azure.com) you are going to get all the resources/services that what you need for your project or application requirement. 
5)Cost effective: It is very much cheap an economical as compared to private cloud or an old legacy system.
6)Reliable: Cloud services are consistently good in quality with equal performance even if we perform multiple enhancements on them.



Different cloud services/cloud service MODELS: 
====================================================
In cloud service model, the cloud providers gives it services in three different ways(i.e. IAAS, PAAS,SAAS)
1)IAAS >>Infrastructure as a Service(Ex of IAAS is : VM, SA, Vnet, Entra ID…etc.)
2)PAAS >>Platform as a Service(Ex of PAAS is : SQL DB, Cosmo DB, Web apps, App services, Azure Bastion host, Azure Firewalls, Logic Apps, Function Apps…….etc.)
3)SAAS >>Software as a Service(Ex of SAAS is : Skype, Gmail, FB, WhatsApp…etc.)
The difference between these 3 service models….is shown below.


7th OCT
================
Azure Cloud Computing is giving us 200+ services
When the tech companies deploying or devlop web projects with below infrastructure


Azure Resources/Services: Anything that you are creating/deploying as part of your application need or project requirement is called as Resources or services.
Example of Resources/Services: 
(i)Virtual machine>>IAAS (ii)Databases>>PAAS (iii)Storage Accounts>>IAAS
(iv)Virtual Networks>>IAAS (v) Load Balancers>>IAAS 
(vi)Docker Container instances>>PAAS (vii)Docker Container Registry>>PAAS (viii)NSG's>>IAAS
(ix)App services>>PAAS (x)Azure Repo's>>PAAS (xi)Azure Pipelines>>PAAS
(xii)Azure CI/CD>>PAAS



On premises               
--------------
Applications
Data
Runtime
Middleware
O/S
Virtualizations
Servers
Storage
Networking

IaaS( Infrascture as a service)            
--------------
Applications
Data
Runtime
Middleware
O/S
Virtualizations--------------------Frome here cloud provider will take
Servers
Storage
Networking

Pa
S( Platform as a service)            
--------------
Applications
Data
Runtime -------------------Frome here cloud provider will take care
Middleware
O/S
Virtualizations
Servers
Storage
Networking


SaaS Software as a service
----------------------------- Completely taken care by cloud
Applications
Data
Runtime
Middleware
O/S
Virtualizations
Servers
Storage
Networking

What is Microsoft Azure: 
=================================
Microsoft Azure is a cloud computing service created by Microsoft for building, testing, deploying, and managing applications 
(Business Applications) and services through Microsoft-managed data centers.

 Advantages/Features of Azure Cloud Computing:
=================================================
As It is a product of Microsoft as Microsoft has launched many frameworks, tools, IDE’s, languages for the applications development 
and all the applications are doing great business from decades, hence clients in the market has got that faith & trust saying Microsoft 
products are reliable, reasonable, efficient and even economical for software applications development.
Compare to AWS the learning/working curve of Microsoft Azure Cloud Computing is small. Azure is easy to work, easy to learn, easy 
to manage, there is no such pre-requisites required to learn Azure, no programming language understanding is required to work in Azure 
cloud computing.
Azure is cheap as compare to other cloud providers (4-12%)
If you are making Azure as your cloud computing partner then it is offering you MS office, WPS office, Lync, skype, share point...etc. 
and other platform available at cheaper cost which ultimately needed for our applications/project developments.
As compared with other cloud providers Azure is offering you many regions/places to deploy/provisioning/creating your resources 
(VM's, SA's, DB's, Vnet, NSG’s, Backup’s...etc.)for our software applications.
Azure is using a very high security algorithms and Hash functions to protect your data and resources what all is been provisioned 
in different regions.
Azure is providing default encryption for all your services that you are provisioning in cloud computing platform, with which it 
is not at all easy for any ethical hacker to hack / hijack the resources which are hosted in Azure Cloud Computing Platform.



Azure Resources/Services:
==============================
A public cloud computing platform, Microsoft Azure offers infrastructure as a service (IaaS), software as a service (SaaS), platform as a service (PaaS), and a serverless model. A constant hybrid cloud, Microsoft Azure is growing in demand with approximately 90% of the Fortune 500 companies using Azure services.
The Azure cloud services are trained and created to deploy and manage even complex apps, through virtual infrastructure. It supports various programming languages, devices, databases, operating systems, and extensive frameworks. Therefore, Azure services intended for the professionals and enterprises offer all-around alternatives to the traditional means of organizational processes, with top Azure services greatly improving the performance.
(or)
Azure Resources/Services: Anything that you are creating/deploying as part of your application need or project requirement is called as Resources or services.


Example of Resources/Services: 
(i)Virtual machine>>IAAS (ii)Databases>>PAAS (iii)Storage Accounts>>IAAS
(iv)Virtual Networks>>IAAS (v) Load Balancers>>IAAS 
(vi)Docker Container instances>>PAAS (vii)Docker Container Registry>>PAAS (viii)NSG's>>IAAS
(ix)App services>>PAAS (x)Azure Repo's>>PAAS (xi)Azure Pipelines>>PAAS
(xii)Azure CI/CD>>PAAS



Azure Resource Groups & Configuration and management of Azure Resource groups for hosting Azure services:
=========================================================
It is a place holder/name/folder basically which hold all our resources in azure. It is a logical container which holds all our resources in Azure portal (or) in Azure resource manager, for each resource that you are creating in Azure must and should be in any of the resource group.  We cannot create a resource in Azure without a resource group.
We can also move the resources from one resource group to another resource group (or) from one subscription to another subscription, but the tools & Scripts associated with moved resources will not work until we update them to use new resource ID’s.
If there are plenty of resources or big size resources in resource group then it might lead a downtime (15-20 mins), so planning of moving resources should be down in non-business hours.
If already an operation of moving resources is in-progress, then at the same time we cannot proceed to move further resources to move to the same resource group. We have to wait until this operation has been completed.
If you are having 10 Resource Group(RG's)...you can take any RG to create your resources, but you should create one RG first before creating anything in cloud portal.
we can create as many as RG's we want in Azure portal
we can keep as many as resources we want in one RG.
we create RGs to divide the cloud services logically....we are creating the infrastructure for applications and every application is having different environments....
In Azure portal RG’s will not charge you any billing/amount the moment you start keeping the resources inside the RG’s then your billing will get started


Subscriptions:
===================
- click on home, click on subscriptions in the seachbar , you will get the amount limit of your account 


Resource groups:
===================
Basics:

- click on home, click on resource group in the serach bar, 
- subscription- azure subscritpino1
  resource group name- BOFA_DEV_RG
  Region:  Austrialia EAST
  Tags:
- Name :      value             Resource
  application: BankofAmerica  
  Owner      : Davic Maclarean
  Enviroment : Dev
  type       : FrontEndResources

- click on create resource group


What is a virtual machine(VM)/Cloud SERVER/Work loads: 
==================================================================
It is a software computer that runs an operating system(o/s) & applications in it. It also contains set of resources in it (ex : O/S disk, Storage disks, Network, IP’s, NSG, NIC… other supporting files, other networks….etc.)
When we are creating a VM then the below components we have to consider broadly
(i)Hardware 
(ii)Subscription 
(iii)Resource group 
(iv)Network 
(v)Storage account 
(vi) O/s(windows or linux)
(vii)Data Disk
(viii)OS Disk
(vii)Load Balancer (viii)VPN….etc.
 When we are creating a VM via portal then we have to fill the below tabs.
(i)Basics (ii)Disks(iii)Networking(iv)management(v)Advanced(vi)Tags(vii)Review+create.
Note: 



VM
===
Project details
subscription: Azure subscription 1
  Resource group: BOFA_DEV_RG
Instance details
Virtual machine name: PLL-VM
Region:   Austrialia EAST
Availablity option 
 - No infrastructure redundancy required 
    I  use this option when i dont want azure to maintain multiple copies or  bakcups of VM
    I  use this option when i dont want Azure to  take care of my VM
    I use this option for  low level enviroments[ Ex: Dev, QA, Staging, Demo..
    if i use this option then i will get less billing
    8GB RAM 2 VCPU's & 127 GB O/S disk>>>9000/month
 - Availablity set
    I  use this option when i  want to azure to maintain multiple copies or  bakcups of VM
    I  use this option when i  want Azure to  take care of my VM
    I use this option for  high level enviroments[ Ex: prod 
    if i use this option then i will get high billing
    8GB RAM 2 VCPU's & 127 GB O/S disk>>>15000/month
    AS will support or protect our VM within in the datacenter failures
      if there is short circuit happened 
 - Availablity zone
    I  use this option when i want azure to maintain multiple copies or  bakcups of VM
    I  use this option when i  want Azure to  take care of my VM
    I use this option for  high level enviroments[ Ex: prod
    if i use this option then i will get high billing
    8GB RAM 2 VCPU's & 127 GB O/S disk>>>20000/month
     it az will protet your vm even in the situations where the complete  data center  gets collapsed
     
 - virtual machine scale set
      These are high availability
9th OCT:
================
- if you select availablity set  in the availablity options   you need select below 

     fault domain(FD) : The network supply, power supply and cooling supply will ber provided thru common channel(single wire)
     
     update domina( UD):  The network supply, power supply and cooling supply will ber provided thru independentchannel(single wire)
     

- if you select availablity zone  in the availablity options   you need select below 
     zone 1,2,3

- if you select virutual mahcine sacla  in the availablity options   azure wil create new vm automatically which is autocscaling


-security: standard
          trusted lanunch virtual mahcines
          confidental virutal mahcines

- Image:  OS
- VM architecture x64
- size   - standard 
- Adminsitrator account 
    username 
    password

-Inboud port rules

select inbound ports  RDP 3389
                    SSH  22
                    HTTPS 443
                    HTTP  80

Disks:

-OS disk size  - Image defualt 
-OS disk type  - Premium SSD 
-delet the VM  - default 
-key manangment - default 
-enable ultra disk compatiblity

Networking:

-Virtual network
-subnet
-public ip
- NIC network security group
- public inbound ports
- seelct inbound  ports
- Load balacnig

Managment

- identiy
- Microsoft entra id
- Auto shutdonw
- bakcup
- siterecovery
- alerts

Advanced

- Then click on connect, clikc on download RDP file, click on connect



vertical scaling:
--------------------
vertical scaling or scale up is when you are making changes in your existing VMS That is called  vertical scaling
whatever the changes is or whatever the changes that your are making

Business case scenario 1:
---------------------------
8GB RAM 2 VCPU's & 127 GB SSD Hardisk
16GB RAM 4 VCPU's & 127 GB SSD Hardisk
- click on PLLVM, click on size,select the size, click on resize


Business case scenario 2:
--------------------------
Add the data disk

- clikc on PLLVM - click on data disk, click on create and attach a new diks
- disk name, storage type- SSD, size -400 
- click on apply, click on connect to VM
- click on diskmanagment
- right click on disk1
- click on new simple volume and click next next next and clikc on referesh,you will see


Business case scenario 3:
--------------------------
- Increase the size of current data disk to 900 gb bye click on disk1 in PLLVM, click on settings, click on size + performance, select the size
  click on save
- in the diskmanagment, click on new volume , click on right click and click on extend volume



Business case scenario 4:
--------------------------
shrink the unutilized size
- click on new volume , click on right click and click on shrink volume


10 oct
---------

ARM templates:
-------------

 -Go to to the virutual machine which was created as PLL-VM
- in the PLL-VM search for export template
- click on export template


- go to template specs
- click on create new template spec
- In basics, name: MyVMdeploymentUsingARM
- Subscription- Azure Subscription1 
  resourcegroup bofa_dev_rG
  Location japanEast
  first version
  version- 0.0.1
- clic on next
- copy your template in edit template
- click on create
- click on MyVMdeploymentUsingARM, click on deploy

The NIC( Network Interface card) will be allotted to our VM by default also we can have 
multiple nics attached to our VM



Creating VM using ARM templates:
=====================================
{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "adminUsername": {
      "type": "string",
      "metadata": {
        "description": "Username for the Virtual Machine."
      }
    },
    "adminPassword": {
      "type": "securestring",
      "minLength": 12,
      "metadata": {
        "description": "Password for the Virtual Machine."
      }
    },
    "dnsLabelPrefix": {
      "type": "string",
      "defaultValue": "[toLower(concat(parameters('vmName'),'-', uniqueString(resourceGroup().id, parameters('vmName'))))]",
      "metadata": {
        "description": "Unique DNS Name for the Public IP used to access the Virtual Machine."
      }
    },
    "publicIpName": {
      "type": "string",
      "defaultValue": "myPublicIP",
      "metadata": {
        "description": "Name for the Public IP used to access the Virtual Machine."
      }
    },
    "publicIPAllocationMethod": {
      "type": "string",
      "defaultValue": "Dynamic",
      "allowedValues": [
        "Dynamic",
        "Static"
      ],
      "metadata": {
        "description": "Allocation method for the Public IP used to access the Virtual Machine."
      }
    },
    "publicIpSku": {
      "type": "string",
      "defaultValue": "Basic",
      "allowedValues": [
        "Basic",
        "Standard"
      ],
      "metadata": {
        "description": "SKU for the Public IP used to access the Virtual Machine."
      }
    },

    "OSVersion": {
      "type": "string",
      "defaultValue": "2019-Datacenter",
      "allowedValues": [
        "2008-R2-SP1",
        "2012-Datacenter",
        "2012-R2-Datacenter",
        "2016-Nano-Server",
        "2016-Datacenter-with-Containers",
        "2016-Datacenter",
        "2019-Datacenter",
        "2019-Datacenter-Core",
        "2019-Datacenter-Core-smalldisk",
        "2019-Datacenter-Core-with-Containers",
        "2019-Datacenter-Core-with-Containers-smalldisk",
        "2019-Datacenter-smalldisk",
        "2019-Datacenter-with-Containers",
        "2019-Datacenter-with-Containers-smalldisk"
      ],
      "metadata": {
        "description": "The Windows version for the VM. This will pick a fully patched image of this given Windows version."
      }
    },
    "vmSize": {
      "type": "string",
      "defaultValue": "Standard_D2_v3",
      "metadata": {
        "description": "Size of the virtual machine."
      }
    },
    "location": {
      "type": "string",
      "defaultValue": "[resourceGroup().location]",
      "metadata": {
        "description": "Location for all resources."
      }
    },
    "vmName": {
      "type": "string",
      "defaultValue": "simple-vm",
      "metadata": {
        "description": "Name of the virtual machine."
      }
    }
  },
  "variables": {
    "storageAccountName": "[concat('bootdiags', uniquestring(resourceGroup().id))]",
    "nicName": "myVMNic",
    "addressPrefix": "10.0.0.0/16",
    "subnetName": "Subnet",
    "subnetPrefix": "10.0.0.0/24",
    "virtualNetworkName": "MyVNET",
    "subnetRef": "[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), variables('subnetName'))]",
    "networkSecurityGroupName": "default-NSG"
  },
  "resources": [
    {
      "type": "Microsoft.Storage/storageAccounts",
      "apiVersion": "2019-06-01",
      "name": "[variables('storageAccountName')]",
      "location": "[parameters('location')]",
      "sku": {
        "name": "Standard_LRS"
      },
      "kind": "Storage",
      "properties": {}
    },
    {
      "type": "Microsoft.Network/publicIPAddresses",
      "apiVersion": "2020-06-01",
      "name": "[parameters('publicIPName')]",
      "location": "[parameters('location')]",
      "sku": {
        "name": "Standard"
      },
      "properties": {
        "publicIPAllocationMethod": "Static",
        "dnsSettings": {
          "domainNameLabel": "[parameters('dnsLabelPrefix')]"
        }
      }
    },
    {
      "type": "Microsoft.Network/networkSecurityGroups",
      "apiVersion": "2020-06-01",
      "name": "[variables('networkSecurityGroupName')]",
      "location": "[parameters('location')]",
      "properties": {
        "securityRules": [
          {
            "name": "default-allow-3389",
            "properties": {
              "priority": 1000,
              "access": "Allow",
              "direction": "Inbound",
              "destinationPortRange": "3389",
              "protocol": "Tcp",
              "sourcePortRange": "*",
              "sourceAddressPrefix": "*",
              "destinationAddressPrefix": "*"
            }
          }
        ]
      }
    },
    {
      "type": "Microsoft.Network/virtualNetworks",
      "apiVersion": "2020-06-01",
      "name": "[variables('virtualNetworkName')]",
      "location": "[parameters('location')]",
      "dependsOn": [
        "[resourceId('Microsoft.Network/networkSecurityGroups', variables('networkSecurityGroupName'))]"
      ],
      "properties": {
        "addressSpace": {
          "addressPrefixes": [
            "[variables('addressPrefix')]"
          ]
        },
        "subnets": [
          {
            "name": "[variables('subnetName')]",
            "properties": {
              "addressPrefix": "[variables('subnetPrefix')]",
              "networkSecurityGroup": {
                "id": "[resourceId('Microsoft.Network/networkSecurityGroups', variables('networkSecurityGroupName'))]"
              }
            }
          }
        ]
      }
    },
    {
      "type": "Microsoft.Network/networkInterfaces",
      "apiVersion": "2020-06-01",
      "name": "[variables('nicName')]",
      "location": "[parameters('location')]",
      "dependsOn": [
        "[resourceId('Microsoft.Network/publicIPAddresses', parameters('publicIPName'))]",
        "[resourceId('Microsoft.Network/virtualNetworks', variables('virtualNetworkName'))]"
      ],
      "properties": {
        "ipConfigurations": [
          {
            "name": "ipconfig1",
            "properties": {
              "privateIPAllocationMethod": "Dynamic",
              "publicIPAddress": {
                "id": "[resourceId('Microsoft.Network/publicIPAddresses', parameters('publicIPName'))]"
              },
              "subnet": {
                "id": "[variables('subnetRef')]"
              }
            }
          }
        ]
      }
    },
    {
      "type": "Microsoft.Compute/virtualMachines",
      "apiVersion": "2020-06-01",
      "name": "[parameters('vmName')]",
      "location": "[parameters('location')]",
      "dependsOn": [
        "[resourceId('Microsoft.Storage/storageAccounts', variables('storageAccountName'))]",
        "[resourceId('Microsoft.Network/networkInterfaces', variables('nicName'))]"
      ],
      "properties": {
        "hardwareProfile": {
          "vmSize": "[parameters('vmSize')]"
        },
        "osProfile": {
          "computerName": "[parameters('vmName')]",
          "adminUsername": "[parameters('adminUsername')]",
          "adminPassword": "[parameters('adminPassword')]"
        },
        "storageProfile": {
          "imageReference": {
            "publisher": "MicrosoftWindowsServer",
            "offer": "WindowsServer",
            "sku": "[parameters('OSVersion')]",
            "version": "latest"
          },
          "osDisk": {
            "createOption": "FromImage",
            "managedDisk": {
              "storageAccountType": "StandardSSD_LRS"
            }
          },
          "dataDisks": [
            {
              "diskSizeGB": 1023,
              "lun": 0,
              "createOption": "Empty"
            }
          ]
        },
        "networkProfile": {
          "networkInterfaces": [
            {
              "id": "[resourceId('Microsoft.Network/networkInterfaces', variables('nicName'))]"
            }
          ]
        },
        "diagnosticsProfile": {
          "bootDiagnostics": {
            "enabled": true,
            "storageUri": "[reference(resourceId('Microsoft.Storage/storageAccounts', variables('storageAccountName'))).primaryEndpoints.blob]"
          }
        }
      }
    }
  ],
  "outputs": {
    "hostname": {
      "type": "string",
      "value": "[reference(parameters('publicIPName')).dnsSettings.fqdn]"
    }
  }
}


Cretion of 2 VM's ARM templates:
==================================
{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "adminUsername": {
      "type": "string",
      "metadata": {
        "description": "Admin username"
      }
    },
    "adminPassword": {
      "type": "securestring",
      "metadata": {
        "description": "Admin password"
      }
    },
    "vmNamePrefix": {
      "type": "string",
      "defaultValue": "MyVM",
      "metadata": {
        "description": "Prefix to use for VM names"
      }
    },
    "location": {
      "type": "string",
      "defaultValue": "[resourceGroup().location]",
      "metadata": {
        "description": "Location for all resources."
      }
    }
  },
  "variables": {
    "availabilitySetName": "AvSet",
    "storageAccountType": "Standard_LRS",
    "storageAccountName": "[uniqueString(resourceGroup().id)]",
    "virtualNetworkName": "vNet",
    "subnetName": "backendSubnet",
    "loadBalancerName": "ilb",
    "networkInterfaceName": "nic",
    "subnetRef": "[resourceId('Microsoft.Network/virtualNetworks/subnets', variables('virtualNetworkName'), variables('subnetName'))]",
    "numberOfInstances": 2,
    "lbID": "[resourceId('Microsoft.Network/loadBalancers', variables('loadBalancerName'))]"
  },
  "resources": [
    {
      "apiVersion": "2018-02-01",
      "type": "Microsoft.Storage/storageAccounts",
      "name": "[variables('storageAccountName')]",
      "location": "[parameters('location')]",
      "kind": "Storage",
      "sku": {
        "name": "[variables('storageAccountType')]"
      }
    },
    {
      "apiVersion": "2018-04-01",
      "type": "Microsoft.Compute/availabilitySets",
      "location": "[parameters('location')]",
      "name": "[variables('availabilitySetName')]",
      "properties": {
        "PlatformUpdateDomainCount": 2,
        "PlatformFaultDomainCount": 2
      },
      "sku": {
        "name": "Aligned"
      }
    },
    {
      "apiVersion": "2018-04-01",
      "type": "Microsoft.Network/virtualNetworks",
      "name": "[variables('virtualNetworkName')]",
      "location": "[parameters('location')]",
      "properties": {
        "addressSpace": {
          "addressPrefixes": [
            "10.0.0.0/16"
          ]
        },
        "subnets": [
          {
            "name": "[variables('subnetName')]",
            "properties": {
              "addressPrefix": "10.0.2.0/24"
            }
          }
        ]
      }
    },
    {
      "apiVersion": "2018-04-01",
      "type": "Microsoft.Network/networkInterfaces",
      "name": "[concat(variables('networkInterfaceName'), copyindex())]",
      "location": "[parameters('location')]",
      "copy": {
        "name": "nicLoop",
        "count": "[variables('numberOfInstances')]"
      },
      "dependsOn": [
        "[variables('virtualNetworkName')]",
        "[variables('loadBalancerName')]"
      ],
      "properties": {
        "ipConfigurations": [
          {
            "name": "ipconfig1",
            "properties": {
              "privateIPAllocationMethod": "Dynamic",
              "subnet": {
                "id": "[variables('subnetRef')]"
              },
              "loadBalancerBackendAddressPools": [
                {
                  "id": "[concat(variables('lbID'), '/backendAddressPools/BackendPool1')]"
                }
              ]
            }
          }
        ]
      }
    },
    {
      "apiVersion": "2018-04-01",
      "type": "Microsoft.Network/loadBalancers",
      "name": "[variables('loadBalancerName')]",
      "location": "[parameters('location')]",
      "dependsOn": [
        "[variables('virtualNetworkName')]"
      ],
      "properties": {
        "frontendIPConfigurations": [
          {
            "properties": {
              "subnet": {
                "id": "[variables('subnetRef')]"
              },
              "privateIPAddress": "10.0.2.6",
              "privateIPAllocationMethod": "Static"
            },
            "name": "LoadBalancerFrontend"
          }
        ],
        "backendAddressPools": [
          {
            "name": "BackendPool1"
          }
        ],
        "loadBalancingRules": [
          {
            "properties": {
              "frontendIPConfiguration": {
                "id": "[concat(resourceId('Microsoft.Network/loadBalancers', variables('loadBalancerName')), '/frontendIpConfigurations/LoadBalancerFrontend')]"
              },
              "backendAddressPool": {
                "id": "[concat(resourceId('Microsoft.Network/loadBalancers', variables('loadBalancerName')), '/backendAddressPools/BackendPool1')]"
              },
              "probe": {
                "id": "[concat(resourceId('Microsoft.Network/loadBalancers', variables('loadBalancerName')), '/probes/lbprobe')]"
              },
              "protocol": "Tcp",
              "frontendPort": 80,
              "backendPort": 80,
              "idleTimeoutInMinutes": 15
            },
            "Name": "lbrule"
          }
        ],
        "probes": [
          {
            "properties": {
              "protocol": "Tcp",
              "port": 80,
              "intervalInSeconds": 15,
              "numberOfProbes": 2
            },
            "name": "lbprobe"
          }
        ]
      }
    },
    {
      "apiVersion": "2018-04-01",
      "type": "Microsoft.Compute/virtualMachines",
      "name": "[concat(parameters('vmNamePrefix'), copyindex())]",
      "copy": {
        "name": "virtualMachineLoop",
        "count": "[variables('numberOfInstances')]"
      },
      "location": "[parameters('location')]",
      "dependsOn": [
        "[variables('storageAccountName')]",
        "nicLoop",
        "[variables('availabilitySetName')]"
      ],
      "properties": {
        "availabilitySet": {
          "id": "[resourceId('Microsoft.Compute/availabilitySets',variables('availabilitySetName'))]"
        },
        "hardwareProfile": {
          "vmSize": "Standard_D2_v3"
        },
        "osProfile": {
          "computerName": "[concat(parameters('vmNamePrefix'), copyIndex())]",
          "adminUsername": "[parameters('adminUsername')]",
          "adminPassword": "[parameters('adminPassword')]"
        },
        "storageProfile": {
          "imageReference": {
            "publisher": "MicrosoftWindowsServer",
            "offer": "WindowsServer",
            "sku": "2016-Datacenter",
            "version": "latest"
          },
          "osDisk": {
            "createOption": "FromImage"
          }
        },
        "networkProfile": {
          "networkInterfaces": [
            {
              "id": "[resourceId('Microsoft.Network/networkInterfaces', concat(variables('networkInterfaceName'), copyindex()))]"
            }
          ]
        },
        "diagnosticsProfile": {
          "bootDiagnostics": {
            "enabled": true,
            "storageUri": "[reference(variables('storageAccountName')).primaryEndpoints.blob]"
          }
        }
      }
    }
  ]
}



Snapshots:
==========
Custome VM:
- go to the vm
- click on server manager
- click on add roles and features
- click on next and add websever ias and click on next

CPATURE THE CUSTOME IMAGE:
==============================
- iN pllvm , Go to the disks
- click on OS disk
- click on the disk of vm, click on create snapshot- 
- You can choose the resource group
- instance details 
Basics
  name - PLLVMdisksteup
  storage tup - Premium SSD
Encryption
Networking
Advanced
tags
review+create

Custom Disk fromPLLVM
=======================
- now go to the snapshot, click  no ccreate a disk 
- disk details
- disk name -CustomeImageDiskfromPLLVM
 - region
 - availablity zone
 - source type

Create a Virtual Machine
- While creating VM choose image CustomeImageDiskfromPLLVM

Flow- New VM ,Installed the S/1==== SNAPSHOT=====Custom Disk fromPLLVM===Virtual Machine


13TH OCT
===========


ARM templates
Custome template deployment
- click on build your own template in editor
- click on edit template
- click on load file


Creation of AZure linux VM:
-----------------------------------
- Click on create new resource group
- basiccs
  subscription azure subscript1
  resource goup name- IRG
  region: austria east

- tags
- review + create
- clikc on VM
basics
- subscript
- vm name
- region
- avaialblity options
- security tyupe
- image
-vm architecture
- size
- adminstattor acount
- username and password
-Inbound ports rules
 select inbound porst http 80 , https 443, ssh22
- now click on create and open cloud shell to lgoing into ubunut
- click on bash
- click on mount storage account
- select we will create a new storage account
- now u will see deployment is in progress

- now connecto ssh -i public key ubuntu@ipaddress
- mkdir frutis

SA
---- 

When ever we want to upload or keep the data in cloud computing then we use,we create storage accounts.
Storage account or storage services is one of means of uploading the data or keep the data in cloud computing.
Storage accounts will accept any type of data... what ever the data is it will accept all types of dtaa


Structured Data[ Ex: Fix no of rows and colunnds.. CSV, Excel..etc]
Semi-Structured Data[ Ex: HTML., ARM templates, XML, YAML..etc]
Un- Structured Data[ Ex: Videos, Images, PDF files, Word, vision diagrams..etc]

Broadly we are having 3 different types of storage  acconts(A)
Standard/Blob SA is having 4 different types of storage offerings

 1) Blob Storage Services>> again divided into 3 different types of blobs
  i) Page Blob
      Here will upload the unstructured data. Videso Images, VM disk, Database backup files, Master database filess..etc]
  ii)Append Blob
      Here will upload the  Resources logs, Historical datam, Structured  data
  iii)Block Blob
      Here will upload the general data, lke project related documents[ words, excel, pdf, images, HTML,ARM templates..etc]


2) File share storage services
     Here will upload flat files, raw files and even other general project relateed documents[ words, excel, pdf, images, HTML,ARM templates..etc]


3) Table Storage Services
     Here  we can upload the data which is in the  form a table[ Rows and column]

4) Queue Storage Services

     Here we can upload the data which is in the  form of a text messages
    [Exlike SMS, Promotional Messages, notifications etc]

    Flipkart:


- Create new resource group
- create new storage accounts
- click on on create new storage accounts
- subscriptions
  Resource group IRG
  Storage account name: pllsa4712
  region: australi East
  preferred AZURE BLOB STAORAGE  or Azure data lake storage Gen2

  performance standard
  redundacny -  LRS LOCALLY REDUNDANT STOARGE - WITIING A SINGLE DATA CENTER IN ONE REGION
                ZRS-ZONE REDUNDANT STORAGE Across 3 avaiabllity zones in the same region
                GRS- GEO REDUNDANT STORAGE Replicates ayynchronouosly to another region
                RA-READ ACCESS GRS- Read access                 Same
                        geio redudntadnt storage 

 Advanced
 security
 - require secure transfer for REST API operation
- allow enabling anonymous access on individual containers
- enable stoarge account key access
- default to microsoft entra authorization in athe azure portal
- Minimum TLS version - version 1.2
- Permitted scop for copy opertaion -from any storage account

Hierarchical Namescpace
Blob storage:
 Allow cross tenant replication
 access tier 
    hot
    cool 

Networking:

publick network  access  - enable
                           disable
                           secure by permiter
public network access scope- enable form all network

You have uploaded some 200 files inside your SA, and nnow some 40 files you have deleted after 3 days or 5 fays
you realizes that the files were important and you want the files back
then ins this scenarios and sitautions the data protection tab is ehelpful

- data protection
  - enable soft delete for blobs
    ddays to retain the deleted blobs
  - enable soft delte for containers
    days to retain delted containers
  -enalb soft delte for file shares

Tracking

- eanble versioning for blobs
- enable blobo change feed

Encryptuon type-  microsf managkey keys 
                  customer managedkey

- click on review +create

Note:
-By default Storage acccount is crate is standard storage account
- blobs-files
- containre- folders



14th OCT
=========
Premum SA:

Yesterday we have deployed Blob/Standard SA
Today will see how we can deploy Premium SA
99.95.. ONLY Just one extra clikcyou  have to for the premium SA.

In bloc/Standard SA you are getting all 4 different stoarge offerrings
In premium SA you are supposed to choose what storage offering you want

Performanc: Premium
Premium account tyope ; page blobs

- You will see only one storage account for premium


- click onn blob storage service in the storage account
- click on add containers
- name
- click on create
- now click on the created container
- click on switch to acces key
- click on upload
- click on browse for files
- you can upgrade from block blob from page blob while uploading by clicking on advanced, page blob is from unstructured data, click on upload
- for apend blob. you can go to any resource click on acitvity log and download the .csv file
- now go to the storage acccount , go to the created coontainer, click on upload click on apend blob , browse and upload the.csv file
  
- for user access
- clickon the file, click on generate SAS
- Permissions
  Read,add,create,writee,delete,permanent delte,tags
- start and expirday date
- allowed ip address
- allowed protocols
     choose https and http
- click on Generate SAS token and URL
- copy Blob SAS URL , past that in the browser , You can see the file
- You can change the access level on the container by clickin on the 3 options , container level, blob level,private level access,container level access, choose blob level 
  the url is direclty accessable



-In File share:

- click on file share
basic
- click name- plfs
- access tier - transaction optimized, hot ,cool
- performance
- 
backup
revidw + create
- click on create file share 
- now got one of the file share, click on browse
- upload the files

Block blob>> that files can be accessed via browser with URL
page blob
append blob

Fileshareblob->> the files cannot be accessed via browser using URL
 Inorder to access the files inised the fileshare we have to host this fileshare on top of a server and this server we called\
it as file share server.

To host a file share on top of a server we have be opening an SMB services on the  network on which our srver is hosted
the port no for SMB services is 445

Once we host the file share on top of a server then this file share will becomes part of the server

Now qyuiclky deply a server.
- click on vm
- resource group -IRG
- image0 window 22
- size -8 g bram
- username and password
- inbound ports http 80, https 443 ,rdp 3389
- login to the server
- open this pc
- right click on network, click on map network drive
- pass the folder details of storage account fileshareblob url, click on that fileshareblob
- click on connect ,click on window ,select any drive letter, coipy the script
- copy the root path in the double quotes and paste in the folder path
- it'ask for 
- azure\pllsa4712 (storage account name)
- for passwrod, go to accesskey in pllsa4712 and copy the key and paste itas a password


Note: Download the AZURE  STORAGE EXPLORER SOFTWARE for Table Storage servcies


Go to the storage account, click on table storage servcids
- click on table
- click on table name- employees Infor,

Using this software we can insert the data inside the table storage services
- click on storage account, click on open in exploreere
-  download the the app from the link and open

- click on the plug, click on subscription, choose azure
- give your maild id
- login and click on open in explorere
- click on plugin again, click on storage account or service
- choose account name and key
- for storage key , in storaage account, click on acess keys copy the key and poaste in account key
- for storage account name you can check and provide from storage account 
- click on next and click on connect
- to detach old storage account from this explorer service, select and click on deetach
- now click on our storage pllsa4712 acount click on tables
-  you can insert the data


16-oct-2025
===================

Inside the storage account we are having 4 different types of storage offerning
  Blob storage sercie
  file share storage service
  table storage srevice
  queue storage service


Queses
- go to stroage acocunt, clck on queus, queue name
- click add message, click on ik
- 


Virutal Network
- Basics
subs
resource group
region
vm nmamew
- security
- ip address
- tags
- review + create

While designing our Vnet in cloud computing based upon the mask bits the No of IP address count will be dcided

10.0.0/16>>

The mask bit and ip counts are inversely proportionali to each other
if you increase the mask bit no then ip counts will decrease in your vnet.
if you decrease the mask bit no then iP counts will increase in your vnet
How many resources tha tyou are having in your projects, depends upon the project size will will decide the iP


17th OCT
==============

Network Security Group( NSG) :
-----------------------------------
In  Network Security Group( NSG) will implement the inbound and outbound traffice for our VM
Here ins Network security group NSG will decide our VM should talk to which services and 
networksecuritygroups

vnets
subnets



loadbalancers
-------------------
-
i f we want lb to balance network traffic between the VM then the VM should be in 
same RG
same network
same region
saem avaialblity set also the vm sshould not have an ip address
we are adding vm isnide the LB not lb inside the vm


VNET Peering
-------------
- Cretae 2 vnets with multiple subnets in different regions 
- click on create resource group
- subc
  resource group name
  region
  review+create
- go to virtual networks
  click on create 
  subscription
  vnet name
  region
  ip addressed
  click on defulat
  subnet name subnet-1
  cliic on create
  review+create
- now do it for second vnet
- now deploy 2 vm on eac vnet
  create virtuma machine
  vm name
  region
  availablitu option no infrascture
  image
  username
  password
  ibound rules
  disks
  networking
  - check vnetname it should second vnetname
  review+create
- now connect to both the vms
- now in first vm
  open the command prompt
- now go back to virtualnetworks
- open one of the vnet click on peering
- perring link name
- virutal network - second vnet name
- remote virtual network peering setting
  allow myvnet 1 to mynet2
  allow myvnet1 to receive forwarde traffic from myvnet2
-  local virutal network smmary
    peering linkname
- local virtual netwokr peering setting
  allow mynet1971 to access  myvnet1973
  allow my net1971 to receied forwarded traffic from myvnet1973
- give the firewall rule
- now try ping to vm2 it will work

Basically at the time of VM creation we are having some basic  provisioning of  ports[ HTTPS, HTTPS, SSH, RDP]
If we want to open/deny apart from this 4 services we use network security group [RDP,SMTP]
If we want to have the complete control on our VM and even teh control of  network traffic inside the VM THEN WE CAN MAKE US OF aZURE FIREWALLS.

AZURE FIREWALLS.
-----------------
- Create resource group
  subscription
  resrouce group
  region
  revew + create

- click on virtual network
  subscription
  resource grpu
  vnetname-firewallvnet
  region
  in ipaddress
  192.168.0.0  /16
  click on defualt
   name auzresubnet
   in subnet purpose- choose azure firewall
   ipuv4 address range-10.0.0.0/16
  now click on add a subnet
  click on defualt
    name vmsubnet
    in subnet purpose- choose azure firewall
   ipuv4 address range-10.0.2.0/24
  click on defualt
    subnet prupose name FIREWALLMANAMENT(forced runneling
    in subnet purpose- choose azure firewall
   ipuv4 address range-10.0.0.0/16
- click on reivwe+create

-Create vm
- click on create vm
- vm name- FWVM
- region
- avaiablity zone - no infstarcuture redundancy required
- security type -standard
- username
-password
- public inbound ports- none
- clic on next
- networking - 
  virtual network firewallvnet
  subnet - myvmsubnet
  network security group - basic
- clickn no reveiw +create

- click on firewalls
- sub
 resource group
 name-MyFW
 region- 
 FIRewall SK - standar
 firewall managment- use fireall rules
 choose a virtual network- use exisiting
 virtual network- FWVnet( MyRG)
 public -  click  on new and give myfwip
 manament public ip addres- clic on new,  name- MyIp
 click on new tags
 review + create

-Now connect to vm, how is that posisblie, now click on n
 firewall, click on myfw-ip, copy Ipaddres
- it will not allow as we have put inbound port non you inorder to enable
- go to firewalls, click on settings, click on rules,.
  clck on add nat rule collection, 
- name= RDPconnection
- prioty 1452
 name- RDPConnection 
 protocal- TCP
 source type- ip address
 source *
 destination address 192.168.10.0 (firewall ip
 destination port  3389 (rdp PORT NO
 translated addres - private IP of the VM
  translated VM- 8080
- Go to firewalls, in PLLFW, click on public ip configuration
- copy ip address and put that in Remote desktip connection


23-OCT-2025:
Azure Bastion Service:
=======================

Create A VirtualNetwork:
------------------------
-click on  virtual networks
-click on create
-subscritipon - Azure subscriptoin1
-resource grup - IR-MG 
-virtual network name- BastionVnet
-region - East Asia
- Ipaddress
  - click on defualt 
  - Name- subnet-1 for VM
  - click on add
  - click on add subnet
  - clik on subnetpurpose azure bastion subnet
  - name-AzureBastionSubnet
  - click on add
- click on next
- click on review_+ creeate

Create Bastions:
-------------------
- click on Bastion
- subscritipon - Azure subscriptoin1
- resource grup - IR-MG 
- name - PLLBastion
- region- Australia East
- Availablity zone - zones 1,2,3
- Tier- standard
- instance count -2
- virutal network- choose - BastionVnet
- subnet- choose AzureBastionSubnet
- publick ipv4 address- choose create new
- public ip address name- Bastion-IP
- In advanced
  choose copy and paste
- click on review +create

Create a Virtual Machine:
----------------------------
-subscritipon - Azure subscriptoin1
-resource grup - IR-MG 
- Virtual Machine name- BastionVM
- Region- Australia East
- Availablity options- No infrastructure redudndancy required
- security tupe -standard
- image
- size - 8 hgp ram 2 vcpus
- username
- password
- inbond port rules - none

- In disks, click on next
- In networking
- virtual network- BastionVnet(IR-MG)
- Subnet- subnet-1
- click on review +create
- now go to BastionVM
- click on connecti via Bastion
- authentication tupe- VM password
- username- bastionVM
- VMPassword- 


Load Balancer will balance the network traffice between the server(webserver1 and webserver2)
Traffic manager profile will balance the network traffic between websites


Websever1/Bangalore@1234>>Australia East
Wevserver2/Bangalore@123>> Australia Centrail

Load Balancer:
================
Create a Virtual Machine1:
----------------------------
-subscritipon - Azure subscriptoin1
-resource grup - PLLRG
- Virtual Machine name- Webserver1
- Region- Australia East
- Availablity options- No infrastructure redudndancy required
- security tupe -standard
- image
- size - 8 hgp ram 2 vcpus
- username
- password
- inbond port rules - Allow selected ports
                      HTTP(80), HTTPS(443), RDP(3389)

- In disks, 
- OS disk size- Image defualt(127 GB)
- OS disk type- Premium SSD( Locally- redundant storage)
- click on next
- In networking
- virtual network- defualt
- Subnet-  defualt
- click on review +create

Create a Virtual Machine 2:
----------------------------
-subscritipon - Azure subscriptoin1
-resource grup - PLLRG
- Virtual Machine name- Webserver2
- Region- Australia Central
- Availablity options- No infrastructure redudndancy required
- security tupe -standard
- image
- size - 8 hgp ram 2 vcpus
- username
- password
- inbond port rules - Allow selected ports
                      HTTP(80), HTTPS(443), RDP(3389)

- In disks, 
- OS disk size- Image defualt(127 GB)
- OS disk type- Premium SSD( Locally- redundant storage)
- click on next
- In networking
- virtual network- defualt
- Subnet-  defualt
- click on review +create

- Now go to virtual machine
- got to webserver1
- click on connect
- cick on download RDP file, enter your credentials
- same way connect to webserver2

Creating webpage in Webserver1:
----------------------------------
- Now in server manager dashboard, In webserver1
- In configure this local server, click on add roles and fetures
- click on next 
- choose webserer IIS,
- click on next, click on install
- Now go to this pc, got to windows C,
- clikc on inetpub,click on wwwroot, There you create a new file 
- In that file wirte as  This is indigo.com
- save as index.html
- Now go to Virtualmachines
- click on webserve1
- in network settings, copy the public ip address and open in the browser
- you will see the page

Creating webpage in Webserver2:
-----------------------------------
- Now in server manager dashboard, In webserver2
- In configure this local server, click on add roles and fetures
- click on next 
- choose webserer IIS,
- click on next, click on install
- Now go to this pc, got to windows C,
- clikc on inetpub,click on wwwroot, There you create a new file 
- In that file wirte as  This is indigo.com
- save as index.html
- Now go to Virtualmachines
- click on webserve2
- in network settings, copy the public ip address and open in the browser
- you will see the page

DNS configruations:
----------------------
- Now click on webserver1
- In settings, click on DNS no required
- In DSN name label- pllservies
- click on save
- Now you will see the DSN configured

- Now click on webserver2
- In settings, click on DNS no required
- In DSN name label- pllservies
- click on save
- Now you will see the DSN configured


Traffice manager:
----------------------
- click on create
- subscription- Azure subscription1
- resource group- PLLRG
- Name- pLLTMP1545
- Routng method- Priority
- click on review + create

Endpoints:
-------------
- click on add
- type- Azure endpoints
- name- p1
- enable endpoint 
- target resource webserver1-ip
- priority-1
- Health checks- enable
- 

- click on add
- type- Azure endpoints
- name- p2
- enable endpoint 
- target resource webserver2-ip
- priority-1
- Health checks- enable
- 

24-octo-2025
Table Storage
====================

Resourccegroup:
- click on resourcegroup
- click on create
- subscription - Azure susbscription1
- Resource group name- PLL-RG
- region Austrial East

Storage account:
- click on  storage accounts
- click on create
- subscription - Azure susbscription1
- Resource group name- PLL-RG
- storage account name- srcsa1948
- region Austrial East
- Preferred storage type- Azure blob storage or azure data lake storage gne2
- Primary workload- High performance computing HPC
- Performance- standard
- Redudancy- Geo redundant storage GRS
- In advanced
- choose require secure transfer for REST API operations
- choose allow enabling anonymous access on individual containers
- choose enable storage account key access
- choose default to microsft entra authoriazation in the azure protal
- minimum TLS version - version 1.2
- click on revew+create

table service:
- After deployment is completed, click on resource
- click on table service
- click on table
- table name- Employeeinof
- click on table
- table name- Salesinfo

microsfo azure storage explorer:
- In microsfo azure storage explorer, click on plugin
- click on subscription, choose azure
- sign in
- again In microsfo azure storage explored, clic on plugin
- click on storage accoutn or services
- choose account name and key
- click on next. You will see connect to azure storage page
- In srcsa1948 storage account, search for access keys click on access keys,
- copy the keys and insert in account key  of  connect to azure storage page
- account name- srcsa1948
- click on conect
- Now in azure storage explorer, click on on srcsa1948(key)
- click down arroa, click on tables, you will see tables employeeinfor and salesinfo
- In Employeeinfo, click on add, 
- In add entity
  PropertyName      type   Value
  Partition key     string madhav
  Rowkey                   jha
  FullName                 MadhavJha
  Techonology              Azure Cloud enginerr
  Location                 Banaglore
  Salry                    40000
- click on insert
- Now you will see the row in the table

Note: iF you want to add the data in table storage services then for sure you have to user Azure storage explorere

query:
- click on query
- selection location     value hyderabad, click on run You will see the data as per your request
export:
- click on export, choose export selected
- save the employeeinfo file. you will see the file in the desktipo
- click on customize columnns and make changes
import:
click on import,click on 3 dots, copy the file path in the filename tabe
- select the file , click on ioepn
- it will show the columnds name and new names if you want to change 
- click on import


42:23

Creating one more storage account
--------------------------
Storage account:
- click on  storage accounts
- click on create
- subscription - Azure susbscription1
- Resource group name- PLL-RG
- storage account name- srcsa1949
- region Austrial East
- Preferred storage type- Azure blob storage or azure data lake storage gne2
- Primary workload- High performance computing HPC
- Performance- standard
- Redudancy- Geo redundant storage GRS
- In advanced
- choose require secure transfer for REST API operations
- choose allow enabling anonymous access on individual containers
- choose enable storage account key access
- choose default to microsft entra authoriazation in the azure protal
- minimum TLS version - version 1.2
- click on revew+create

- Now got to srcsa1949 
- In overview, click on file services
- click on file share
-  name- plfs
-  click on next
-  uncheck enable backup
-  click on create
-  in plfs , click on upload , and updload the files
- 


- Now got to srcsa1948
- In overview, click on Blob storage service
- click on container
- name- srccon
- click on create
- click on srccon
- click on upload
- and upload the files


Praveen>>srcsa1948>Blob Storage srvice>>3 files
Sunil>>srcsa1948> File services>> 2 files

Every Storage account is having a uniqueue key and connection string
Once you shared the key or the connection string of the SA then the user will get the  admin access  to your Stroage account

- In srca1948, serach for access,, click on access keys, Give the acces keys to prrvaee
-  Now praveen praveen has to select account name and key see below process
- again In microsfo azure storage explored, clic on plugin
- click on storage accoutn or services
- choose account name and key (Same way you can do it for connection string and shared access signature URL)
- you need to give account name srcsa 1948
- account key


Note:Same way you can do it for connection string and shared access signature URL



To signing out on storage account: right click on it and you will see 

You have to give the access to the user also at the same time you hvae to ensure that  the user should not delete or modkfy tyour data or files inisde the SA
In this case we use an another approach called shared access signatures

- Now got to srcsa1948
- search for sas, click on shared access signature
- you will option to set the signatures
- In allowed services- choose blob
- In allowed resource tyep- choose service and container
- In allowed permission, choose read, write, deltete ,list ,add create
- Blob versioning permissions
 choose enalbes deletion of versions
- In allowed blob index permissions
  choose read/write and filter
 - now come to Microsoft azure storage explored, select shared acess signature


27.oct.2025
------------


Azure cloud services is been divided into 3 categories
------------------------------------------------------------------------------
IAAS>> Infrastrure  as service >> Virtual mahcines>> Web apps developments, build, deploments, sever maintenance, configurations
PAAS>> Platform as service >> App service>> Web application development, build and deployment
SAAS>> Software as service >>

Here we are learing how we are hosting/migrating the web app which is  in my laptiop to azure cloud computing services.



PAAS Service:
----------------

Azure App Services::
------------------------
Azure App Service is a fully managed Platform as a Service (PaaS) offering from Microsoft for building, deploying, and scaling web applications, mobile backends, and REST APIs. It simplifies web hosting by handling the underlying infrastructure, allowing developers to focus on their code. App Service supports various programming languages and frameworks, including .NET, .NET Core, Java, Node.js, PHP, and Python, and can run on both Windows and Linux. 
Azure App Service is a platform that lets you run web applications, mobile back ends, and RESTful APIs without worrying about managing the underlying infrastructure. Think of it as a powerful web hosting service that takes care of all the heavy lifting for you, so can focus on creating great applications.
App Service supports a variety of web stacks: .NET, Java (in Java SE, Tomcat, and JBoss flavors), Node.js, Python, and PHP, and can run them on both Windows and Linux. Or, if your app is containerized, you can just deploy it as a custom container.


Deploying Web Apps in Azure App services(As PAAS):
========================================================
Azure App Service lets us create apps faster with one-of-a kind cloud service to create enterprise-ready web app and mobile apps quickly and easily for any platform or device and deploy them on a scalable and reliable cloud infrastructure.
Azure App Service is an HTTP-based service for hosting web applications, REST APIs, and mobile back ends. we can develop in our favourite language, be it .NET, .NET Core, Java, Ruby, Node.js, PHP, or Python. Applications run and scale with ease on both Windows and Linux-based environments.
App Service not only adds the power of Microsoft Azure to our application, such as security, load balancing, autoscaling, and automated management. We can also take advantage of its DevOps capabilities, such as continuous deployment from Azure DevOps, GitHub, Docker Hub, and other sources, staging environments, custom domain, and TLS/SSL certificates.
With App Service, we pay for the Azure compute resources that we use. The compute resources we use are determined by the App Service plan that we can run our apps on.



HOSTING .Net Web apps in aZURE PAAS SERVICES:
======================================================
Step1: 
Open Project solution files in VS-2022 in laptop>>
Build the project>>
Run the project to ensure the application is up and running in our local laptop(local repo or Private cloud)


- First open the code in visual code
- click on build 
- now run the code 


Step2(Migrating/Hosting .Net web Application in cloud):
Right click on project>>Publish>>+New Profile>>Azure>>Azure App Service(Windows)>>Next>>Select (or) Login to the Azure Account(in which we want to create an App services)>>
Create a new instance and fill the details as below
Name: WebApp1791(any name)
Subscription Name: choose accordingly
Resource Group: NareshRG(any name)
Hosting Plan: WebAppp1(any name)
And finally click on Create>>Finish>>Close>>Publish
Publish>>
Search for App Services in azure portal and deploy an app service in Azure portal(ensure that you deploy an app service plan that will support the custom domain)>>
now click on browse after the App service got deployed to check whether the App services is up and running in Azure portal>>right click on the solution>>publish

- click on azure, click on azure app service
- click on next 
- after singin
- target- azure subscripton1
- app service - clickon create new instances
- Name- PLLWebapp1548
- Subscription name- Azure Subscription 1
- Resource group- MyRG
- Hosting plan
   LOCATION
   SIZE
- click on ok
- click on create
- You will see an app service PLLWebapp1548 will be created in the MYRG folder
- click on close, click on oka,
- app will be published

- In azure, serach for app services
- click on appservices
- you will see PLLWebapp1548
- copy the url you will see the webpage in the browser

Step3(making enhancements in the project code @ on-prem & deploying directly in cloud):
Now in VS expand Views(folder)>>Shared>>_Layout.cshtml>>in line No:13 instead of Application name mention as NareshIT>>click Save and Save All(at the top)>>Build the project again>>ensure build should get succeed>>right click the solution publish
Hence here we have deployed/migrate our .Net web application on Azure App services which is offered as Platform as service(PAAS) in cloud platform..


- After editing the code on live.
- right click on the project
- cilck on publish


Kubernetes Services:
======================
1. It’s basically a container orchestration software or an orchestration
engine and also an open-source platform for deploying and managing
containerized applications.
2. The functionalities of Kubernetes Services are container deployment,
scaling &amp; descaling of containers/pods and containers load balancing.
3. Kubernetes is not a replacement for Docker, but it can be considered as
a replacement of Docker Swarm, Kubernetes is significantly more
complex than Swarm and requires more work to deploy.
4. This was introduced by google, written in Go/Golang and donated to
cloud native computing foundation (CNCF) in 2014.
5. Kubernetes v1.0 was released on 21 st July 2015 and the current stable
release of K8S is version v1.18.0.


Key features/Advantages of Kubernetes services(K8S):
(i)Automated scheduling: K8S provides advanced scheduler to launch
container on cluster nodes based on their resource requirements and other
constraints while not sacrificing the availability
(ii)Self-healing capabilities: it allows us to replace and reschedule containers
when nodes die, it also kills containers that don’t respond to user defined
health check and doesn’t advertise them to clients until they are ready to
serve.
(iii)Automated rollouts &amp; rollbacks: Kubernetes rolls out changes to the
application or its configuration while monitoring application health to ensure it
doesn’t kill all our instances at the same time. If something goes wrong with
K8S then we can roll back the changes
(iv)Horizontal scaling &amp; Load Balancing: K8S can scale up and scale down the
application as per the requirements with simple command, using a User
Interface or automatically based on CPU usage. K8S supports both manual
scaling and auto scaling of PODS(Containers)
(v)Service Discovery &amp; Load Balancing: With K8S there is no need to worry
about networking and communication bcoz K8S will automatically assign IP
addresses to containers and a single DNS name for a set of containers, that can
load balance the traffic inside a cluster, containers get their own IP so we can
put a set of containers behind a single DNS name for Load Balancing.

(vi)Storage Orchestration: with K8S we can mount the storage system of our
choice, we can either opt for local storage or can choose a public cloud
provider such as Azure, AWS, GCP or perhaps can use a shared network
storage system.
6. K8S is widely used bcoz its an open source and it has lot of features
which are not available in docker swarm and its been implemented by
google and has a wider community (means lot of people working on this
and ready to help)
7. K8S works in declarative mode, like what we want to deploy, how many
replicas we want….etc. and rest of the things will be taken care by K8S,
like it will schedule the containers, manage the containers all….
Kubernetes Architecture: Kubernetes implement a cluster computing
background, that everything will work from inside a Kubernetes cluster, this
cluster is hosted by one node acting as a master of the cluster and other nodes
as worker/slave nodes, which do the actual Containerization, as shown below.

Kubernetes Components:
Web UI (Dashboard): Dashboard is a web based Kubernetes user interface, we
can use dashboard to deploy containerized applications to a Kubernetes
cluster, troubleshoot our containerized application and manage the cluster
itself along with its available resources.
Kubectl: This is a command line configuration tool(CLI) for K8S which is used
to interact with master node of K8S, kubectl has a config file called Kubeconfig,
this file has the information about server and authentication information to
access the API server.

Master Node:
The master node is responsible for the management of K8S cluster, it is mainly
the entry point for all the administrative task, it handles the orchestration of
the workers nodes, there can be more than one master node in the cluster to
check for fault tolerance.
Master Nodes Components: It has below components that take care of
communication, scheduling and controllers
(i)API server: Kube API server interacts with API, it’s a frontend of the
Kubernetes control plane. Communication center for developers, sysadmin and
other Kubernetes components
(ii)Scheduler: Scheduler watches the pods and assigns the pods to run on
specific hosts. The scheduler will try to schedule the unscheduled pods in
NODES with the help of Kubelets
(iii)ETCD: It’s a key value data store, K8S will maintain all the cluster
info like nodes, pods, services, volumes…etc, it’s basically a Database
for K8S, it’s a simple distribute key value store, K8S uses ETCD as it’s a
database to store all cluster data, some of the data stored in ETCD is job
scheduling information, pods, state information and etc.
Worker Nodes/Slave Nodes:
1. Worker nodes are the nodes where the application actually running
in the K8S cluster, it is also known as minion, each worker nodes
are controlled by the master nodes using Kubelet process
2. Container platform must be running on each worker nodes and it
works together with kubelet to run the containers, this is why we
use Docker engine and takes care of managing images and
containers.
3. we can also use other containers platforms like core OS, Rocket
Work NODES Components:
(iv)Kubelet: Kubelet is the primary node agent runs on each node and
reads the container manifests which ensures that containers are running
and healthy, its make sure that containers are running in a Pod, the
Kublete doesn’t manage the containers which were not created by
Kubernetes.
Kube Proxy:

1. Kube porxy enables the Kubernetes service abstraction by
maintaining network rules on the host and performing the
connection forwarding.
2. Kube proxy maintains network rules on nodes, these network rules
allow network communication to our pods from inside or outside of
our cluster
3. It helps us to have a network proxy and load balancer for the
services in a single worker node.
4. Service is just a logical concept, the real work is being done by the
Kube-proxy pod that is running on each node
5. It redirect the requests from cluster IP(virtual IP Address) to Pod
IP.
Container Runtime: Each node must have container runtime, such as
Docker, rkt, or another container runtime to process instructions from the
master server to run the containers
Azure Kubernetes Services(AKS) : It is a managed service that allows
us to quickly deploy and manage clusters(collection of nodes/servers). It
is an open source system for container orchestration for
Deployment/Management &amp; Scaling applications. AKS helps us to
manage containerized application (may be 100&#39;s/1000&#39;s...) in different
environments(windows, linux..etc).
When we need to create a cluster in Azure then we go for Azure
Kubernetes Services(AKS),it is offered as PAAS. Here we can create a
cluster of either 3/4/5…etc nodes as per our application requirement. We
can create a cluster of max 100 nodes in AKS.

We can also set the auto scaling of this cluster based up on the
requirement
36. while creating the AKS cluster in Azure we have to consider the
following things.

(i)Kubernetes cluster name
(ii)Region
(iii)Availability zone
(iv)Kubernetes version
(v)Node size
(vi)Node count
(vii)Add node pools
(viii)Enable virtual nodes/Virtual machine scaleset
(ix)Role Based Access Control
(x)AKS-managed Azure Active Directory
(xi)Network configuration…etc. etc

1. We can add node pools in AKS cluster as we need for our
application, the Operating system type for each node pool we can
choose either (Windows or Linux)
2. Whatever the deployment that we do in Kubernetes cluster that all
deployments comes under pod, and if we need an autoscaling of
pod then we can make the virtual node feature as Enabled, what
is the benefit of pod autoscaling?? Or what is Pod?? Pod will get
placed inside the node under node cluster and if the load is getting
increased on pod then it will not do the autoscaling of node
instead, if the space is available in the node then first it will
enhance/autoscaling of pod, and we deploy our applications inside
the pods
3. Cluster subnet: whatever the cluster has been created for our
AKS from this subnets our cluster nodes will get the IP’s if we are
having multiple subnets created..
4. Virtual node subnet: The IPs assigned to pods will get assigned
from this virtual node subnet
5. Kubernetes service address range; To make communicate the
pods from one another pod we use service address range.

Note:
Azure kuberntest cluster is a combination of multiple node pools
Each node  pool can have a different O/S Windows or linux]
Node pool is a combination of multiple nodes
Node is nothing but a server/VM
Each node can have multiple pods in it
This pods we can also called a containers
On top of this pods we are hosting our applications


Implementation of AKS Cluster:
-------------------------------------------
In Azure portal search for Kubernetes services&gt;&gt;+Create&gt;&gt;Create a
Kubernetes cluster and then fill the details accordingly.
Subscription: pick the subscription accordingly/mostly free trial
Resource Group: MyRG
Cluster preset configuration: Dev/Test
Kubernetes cluster name: aksdemo1
Region: East US
Availability zones: Zones, 1,2,3
AKS Pricing tier: Free
Kubernetes version: 1.28.5(default)
Automatic upgrade: Enabled with patch(recommended)
Leave rest of the values to default&gt;&gt;click Next: Node pools&gt;&gt;Click
Next: Networking&gt;&gt;Network configuration: Azure CNI Node
Subnet(in networking tab)&gt;&gt;Click Next: Integration&gt;&gt;Click Next:
Advance&gt;&gt;Next: Tags&gt;&gt;click Review+Create&gt;&gt;wait for some time till
the validations gets completed&gt;&gt;Click Create to provision the
Kubernetes cluster.
Configuring Kubectl to communicate/connect to AKS cluster:
Click on cloud shell&gt;&gt;Create a Storage account&gt;&gt;choose Bash&gt;&gt;wait
for some time till the bash terminal gets ready&gt;&gt;
Type clear&gt;&gt;command to clear the screen
az aks get-credentials --resource-group MyRG --name
aksdemo1&gt;&gt;Command to connect AKS cluster
MyRG&gt;&gt;Resource Group name &amp; aksdemo1&gt;&gt;AKS name

Note: If we are getting message as below after passing the above
command then simply say y and hit enter as shown below.
A different object named aksdemo1 already exists in your
kubeconfig file.
Overwrite? (y/n): y
kubectl get nodes&gt;&gt;command to list kubernetes worker nodes, this
command gives us the information about the nodes like status, age,
version….etc.
kubectl get nodes -o wide&gt;&gt;command to get the further details of
Kubernetes worker nodes….like internal IP address of our Kubernetes
cluster nodes, Age of the nodes, O/S of the nodes, Status……etc. etc…
kubectl get namespaces&gt;&gt;Command to get all the namespaces of
Kubernetes cluster
Clear&gt;&gt;commands to clear the screen

kubectl get pods --all-namespaces&gt;&gt;Commands to get the pods of
all namespaces

installing AKS CLI in our local laptop from below link:
https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest
Go to the above link&gt;&gt;go to Installation box&gt;&gt;click on Install – Windows&gt;&gt;click
install or update&gt;&gt;click Latest MSI of the Azure CLI(64 bits)&gt;&gt;now the dll(dynamic
link library) will get downloaded in our local laptop wait for some time&gt;&gt;Now in
search type command prompt&gt;&gt;right click&gt;&gt;run as administrator&gt;&gt;and pass the
command as
az login&gt;&gt;command to login to Azure subscription&gt;&gt;wait for some
time then it will show all the details of our subscription. then pass
the below command and hit enter

az aks install-cli&gt;&gt;Commands to install Azure CLI in our laptop, and it
also download and install kubectl, the Kubernetes command-line
tool. download and install kubelogin, a client-go credential (exec)
plugin implementing azure authentication…. etc. After passing this
command wait for some time and will get a message as below
The installation directory &quot;C:\Users\wasay\.azure-kubelogin&quot; has
been successfully appended to the user path, the configuration will
only take effect in the new command sessions. Please re-open the
command window.
Now close the command prompt and reopen again as administrator.
Cls&gt;&gt;Command to clear the command prompt screen in our local
laptop.
az aks get-credentials --resource-group MyRG --name aksdemo1
kubectl get nodes&gt;&gt; command to list kubernetes worker nodes, this
command gives us the information about the nodes like status, age,
version….etc…doing this time from our local laptop command
prompt…not from cloud shell.

kubectl get nodes -o wide&gt;&gt; command to get the further details of
Kubernetes worker nodes…. like internal IP address of our
Kubernetes cluster nodes, Age of the nodes, O/S of the nodes,
Status……etc. etc… doing this time from our local laptop command
prompt…not from cloud shell.
Explanation of 01-Create-AKS-Cluster folder files for sample
application deployments on Kubernetes cluster:
The below 2 are called Kubernetes manifest files.
(i) 01-Deployment.yml (ii) 02-LoadBalancer.yml

replicas:2&gt;&gt;means on 2 instances our application is going to run

name: myapp1-deployment&gt;&gt;application deployment name
image: stacksimplify/kubenginx:1.0.0&gt;&gt;Here the nginx application is
pacakged in kube nginx 1.0.0 version
containerPort: 80&gt;&gt;container is hosted on port No:80
LoadBalancer.yml&gt;&gt;with this file we are creating a service called
Load Balancer whose port No is 80 and container port is also 80
Deploying an application in Kubernetes pods:
Step1: Place this folder 01-Create-AKS-Cluster in below path in our
local laptop
C:\Windows\System32
Step2: Search for command prompt&gt;&gt;right click run as administrator
and pass the below commands(execute the commands in
sequence…)
az aks get-credentials --resource-group NareshRG --name
aksdemo1&gt;&gt;Commands to get the Kubernetes cluster details
kubectl get nodes&gt;&gt;Command to get the nodes details
cd 01-Create-AKS-Cluster/&gt;&gt;Command to go inside this folder
kubectl apply -f kube-manifests/&gt;&gt; Command to deploy an
application on Kubernetes cluster pods
kubectl get pods&gt;&gt;Commands to verify the pods in which the
application is deployed and running
kubectl get deployment&gt;&gt;commands to verify that our application
deployment has been happened successfully in our Kubernetes
cluster pods

kubectl describe pod myapp1-deployment&gt;&gt; Commands to see
what are the events occurred on the pods and application which we
have deployed on Kubernetes cluster
cls&gt;&gt;Commands to clear the screen.
Kubectl get services&gt;&gt; Commands to see what services have been
deployed like Load balancer IP, cluster IP, Kubernetes, app
deployments, Port No’s…...etc. etc.
Testing the application deployment in Kubernetes Pods:
Take the Load balancer External IP(as shown in image below) and
paste it in Microsoft Edge browser then here will can see the
application opened in browser that we have deployed in our Azure
Kubernetes cluster pods

The application which is hosted on Kubernetes pods will appear in
the browser something like below

Kubectl delete -f kube-manifests/&gt;&gt; Commands to delete the
application that we have deployed on Azure Kubernetes cluster
pods…wait for some time until it deletes the application and pods…
And now if we do again Kubectl get pods

Then we find the result as No resources found in default
namespace, means here all the pods and application that we have
deployed is deleted except the Kubernetes cluster.

Hence here in Kubernetes cluster we have deployed the pods, in the
pods we have deployed the application, we have tested/browse the
application on the browser and finally we have deleted the same.

AKS Implementations:
--------------------------

- create a resource group
- subscription-AzureSubscription1
- resource group name -= MyResourceGroup
- region - Austrualia East
- click on review create

- go to kubernete services
- click on kubernetes cluster
- Subscruption- AzureSubscription1
- Resource group- MyResourceGroup
- Cluster preset configuration- Dev/Test
- Kubernetes Cluster name- aksdemo1
- Region- Australia East
- Fleet Manager-  none
- Avaialblity zone- none
- AKS pricing tier- Free ( The cluster managment is freem but you will be 
   chareded for VM, storage and menetworking usaged. Best for experimenting learning simplet etesting or workloads with fewer tthant 10 nodes)

-  kuberbetes version
-  Automatic upgrade- Enabled with path (recommemended) 
     automatic updgrade scheduler  Every week on sunday (recommend)
-  Node security channel type- Node image
    Security channel scheduleer- Every week on sunday (recommend)
- Authententication and Authorization - Local accounts with kuberntes RBAC

In Node Pool
- click on defualt node pool
- node pool name - Linuxnodepoo;
- availablity zone- choose zone1,2,3
- node size- 2 vcpus 8 gb memory
- scalae method - auto scaled recommendd
- Mininum node count- 2
- Maximum node count -3
-  Enable virutal node- chose
In Networking
- defualt
In Integrations
- defualt
In Monitoring
- chooose enalbe container logs
- log anatlytics workspace- choose default
In security
- choose default
In Advanced-
 - choose default
- click on review _ create

- Once it is deployed, click on aksdemo1
- click on cloud shell on top right
- choose bash
- choose your subscription
- choose we will crate s storage account for you
- click on next
Command to connecto AKS Cluster
- az aks get-credentials --resource-group MyResourceGroup --name aksdemo1 (clustername)
- kubectl get nodes
- kubectl get nodes -o wide
- kubectlt get namespaces
- clear command
- kubeclt get pods --all-namespaces
graphaically you can see in Setting in nodepools, in Linux node pools, click on nodes

Installing AKS CLI direclty in our local laptop to connecti to kubernetes cluster:
----------------------------------------------------------------------------------------
- In our terminal give az login
- it will navigate to you to the deployed cluster
- login





3 NOV 2025
------------

Containerization:
Containerization is the packaging of software code with the operating
system (OS) libraries and dependencies required to run the code to create a
single lightweight executable—called a container, containers runs
consistently on any infrastructure. More portable and resource-efficient
than virtual machines (VMs), containers have become the de
facto compute units of modern cloud-native applications.
Containerization allows developers to create and deploy applications faster and
more securely. With traditional methods, code is developed in a specific
computing environment which, when transferred to a new location, often
results in bugs and errors. For example, when a developer transfers code from a
desktop computer to a VM or from a Linux to a Windows operating system.
Containerization eliminates this problem by bundling the application code
together with the related configuration files, libraries, and dependencies
required for it to run. This single package of software or “container” is
abstracted away from the host operating system, and hence, it stands alone
and becomes portable(able to run across any platform or cloud, free of issues)
Docker containers:
 Each container has its own process, storage but host O/S is common for all
the containers, if anything goes wrong with App1 then their won’t be any
impact on other applications (like App2, App3…etc) as there are
independent with each other and that’s the beauty of containerization.
 Virtual Machines are heavy in weight and containers are light in weight,
containers can be created anywhere on top of physical machines, virtual
machines.
 As we can in above image, we can create a containers which has
application/application code and its software’s, Environment variables,
agents, Frameworks and dependencies…etc.
Containers: Containers will carry our applications and its dependencies.
Containers are light in weight, it does not contain the CPU and memory as
much as a VM, the container does not have an operating system, containers
are portable which can be moved from 1stenv to another environment(env)

2

Docker in Brief:

Docker_Training.pdf

Docker container in Azure Cloud Computing:
Containers:
A container is a standard unit of software that packages up code and all its
dependencies, so the application runs quickly reliably from one computing
environment to another.

 In case of VM’s there’s always a host, the host is created from the
infrastructure on top of which there’s a hub hypervisor running and this
hypervisor is responsible for hosting virtual machines and managing
them, so there’s always a virtual machine on which we always have
something called guest operating system, therefore we need to
virtualize an entire operating for we to be able to host our application
and we need to this again for every single application and when it comes
to containers we also have a host and this host again has an
infrastructure, but whats difference here is that we have a host
operating system and top of which there’s something called run time
and this run time is responsible for hosting and managing containers,
but what is good here is that from here onwards we can just host

3
containers, we no longer need that guest operating system for each
application and each container.
 Therefore releasing a lot of unnecessary resources and as such allowing
us to host more containers in more applications. So the main difference
is here are first of all there’s less development overhead and developers
don’t need to create container and they don’t need to create those
images for virtual machines which takes a lot of time creating containers
takes just minutes and if we know and if we have a priority prepare
scripts in just couple of seconds and we have seen there is there’s no
guest operating system’s, so there’s much less resources consumed and
which also means since there’s not guest operating system loaded into
the container and the file itself is in much smaller size, its from hundreds
of megabytes down to 20 or 30 megabytes of size.
 Since the small size is there and the less consumption is required that
means they also are starting up faster and we can get our containers
running in just seconds and as we are not running the O/S this against
means there’s much less updates that we need to do, therefore there’s a
reduced and simplified updating process that we need to implement for
managing our applications
Advantage of containers as compared to Virtual Machines:
⮚ Less development overhead.
⮚ Less resources(RAM, VCPU’S, Percentage CPU’s, processing, Disk
consumption…etc) consumed.
⮚ Smaller size
⮚ Faster start-up
⮚ Reduced and simplified updates



Azure Container Instances(ACI):
Azure container instances offer the fastest and simplest way to run a container
in Azure, without having to provision any virtual machines and without having
to adopt a higher-level service.
Container Group: It is just a grouping of multiple containers where we can host
multiple applications in it, in containers we host each application on port No’s
(like port 80, 5000…etc)to allow public connectivity and which allows us to get
a public ip and a public DNS name for our container and hence a public
connectivity can be established and in this way we can host our web

4
applications using containers(docker containers) in Azure cloud computing
platform.
Key Benefits of using Azure Docker Container Instances(ACI):
⮚ It provides fast startup times – in just few seconds ACI can start up
containers
⮚ It provides public IP &amp; DNS names
⮚ Custom Sizes
⮚ We can host both Linux and Windows containers
⮚ We can get persistent(continuing to exist ) storage
⮚ It even allows us Virtual Network deployment


Demo’s on Azure Docker Container Instances (ACI):

1)Simple web application with Docker container image on Azure Container
Instance(ACI) on top of Linux O/S
2)Custom image/WebApps using node js application and will deploy this image
to ACI after this will deploy Docker container registry then container instance
for hosting application on Docker container.
Note: Try to do these all labs in Azure Paid Subscription, in Free trial the
docker libraries, dll’s are not supported.

Demo 1: Using Custom image docker file to host on top of Docker container
instance.
Creating Docker container instances with Azure CLI(in Azure portal cloud
shell)
Step1:
command to create a Resource Group:
az group create --name myResourceGroup --location JapanEast
myResourceGroup&gt;&gt;Resourcegroup name (or) we can give any
Step2:
command to create docker container instance:
az container create --resource-group myResourceGroup --name mycontainer1771 --image
ashfaque9x/my-html-website --dns-name-label aci-demo1771 --ports 80
myResourceGroup&gt;&gt;Resource Group name (or) we can give any

5

mycontainer1771&gt;&gt;container instance name (or) we can give any
--image ashfaque9x/my-html-website&gt;&gt;registry in which our image/app is store (or) ny name
aci-demo1771&gt;&gt;DNS name (or) we can give any
80&gt;&gt;Port No on which we are hosting our Application on top of the docker container instance
Step3:
Wait for some time until the docker container instance get provisioned in
Azure cloud platform, now copy the IP address/FQDN of the container instance
and paste it in a browser to view the application hosted on Azure docker
container instance.
Deploying via Azure portal:
1. Login to Azure portal&gt;&gt;search for container instances&gt;&gt;create&gt;&gt;and fill
the below details:
Subscription: Paid subscription (or existing whatever)
Resource Group: any
Container name: starbucks-cafe
Region: Japan East
Availability zone: none
SKU: Standard
Image Source: Other registry
Image Type: Public
Image: ashfaque9x/my-html-website [ Here ashfaque9x&gt;&gt;Username &amp;
my-html-website&gt;&gt;Image name]
Size: keep as default
Click next on Networking tab
DNS name label: cromaservices &gt;&gt; and leave all rest values as is and
finally click on Review+Create and provision the first ACI
Now copy and paste the IP address or FQDN of the ACI in another
browser then will see Starbucks Cafe Dynamic website is hosted on top
of our Docker container Instance.

Demo 2: Practical Implementation of ACI:
Step1:
command to create a Resource Group:
az group create --name myResourceGroup --location JapanEast

6

myResourceGroup&gt;&gt;Resourcegroup name (or) we can give any
Step2:
command to create docker container instance:
az container create --resource-group myResourceGroup --name mycontainer1773 --image
mcr.microsoft.com/azuredocs/aci-helloworld --dns-name-label aci-demo1773 --ports 80
myResourceGroup&gt;&gt;Resource Group name (or) we can give any
mycontainer1773&gt;&gt;container instance name (or) we can give any
--image ashfaque9x/my-html-website&gt;&gt;registry in which our image/app is store
aci-demo1773&gt;&gt;DNS name (or) we can give any
80&gt;&gt;Port No on which we are hosting our Application on top of the docker container instance
Step3:
Wait for some time until the docker container instance get provisioned in
Azure cloud platform, now copy the IP address/FQDN of the container instance
and paste it in a browser to view the application hosted on Azure docker
container instance.
Deploying via Azure portal:
 Login to Azure portal&gt;&gt;search for container instances&gt;&gt;create&gt;&gt;and fill
the below details:
Subscription: Free trial (or existing whatever)
Resource Group: any
Container name: give any name &gt;&gt;this is our container group name
actually
Region: give any region
Image Source: QuickStart images
Image: mcr.microsoft.com/azuredocs/aci-helloworld:latest &gt;&gt;so, here
we are pasting the URL which is a container containing node.js
application with helloworld message in Microsoft content registry with
microsoft.com
Size: keep as default
Click next on Networking tab
DNS name label: intelliservices&gt;&gt; and leave all rest values as is and
finally click on Review+Create and provision the first ACI
 Now copy and paste the IP address or FQDN of the ACI in another
browser then will see Welcome to Azure Container Instances! &gt;&gt;Now

7
this indicates our simple web application running on docker container
image via ACI.

Demo 3: Custom image/WebApp using node js application and will deploy
this docker image to Azure Docker Container Instance
click on cloud shell&gt;&gt;click on Bash&gt;&gt;Mount a Storage Account&gt;&gt;choose
Storage account subscription&gt;&gt;Apply&gt;&gt;click the radio button We will create
a storage account for you&gt;&gt;Next&gt;&gt;It pops up saying deployment is in-
progress and then patiently wait for sometime like some 2-3 minutes of
time the Bash terminal with all its background gets ready and now pass the
below command and hit enter
git clone https://github.com/Azure-Samples/aci-helloworld.git&gt;&gt;this we
are cloning the git repository of the container that we deployed in above
demo
type ls and hit enter&gt;&gt;and here we see we have a folder aci-helloworld
type cd aci-helloworld/ and hit enter&gt;&gt;to go inside the aci-helloworld
folder
type code . and hit enter&gt;&gt;in cloud shell we pass this command to open an
editor that looks very similar to visual studio code and now here an editor
will get open with .git and app folder with multiple files in it and also some
other files
click on index.html file inside the app folder and remove the complete
coding of tag &lt;svg&gt; to &lt;/svg&gt; and type in tag &lt;h1&gt; Welcome to Azure
Docker Container Instances Classes for Naresh IT Students!
&lt;/h1&gt;
click on top right three dots and click on save to save the changes and close
this editor by clicking on close(below)
Docker Container Registry:
It is an inbuild service for hosting containers for more than just other
container instances, we can also use it with Kubernetes services, fabric
services…etc and here this container registry will allow us to build a docker
container and host it

8
Now come to Azure portal and search for container
registries&gt;&gt;create&gt;&gt;and fill the details
Subscription: take any
Resource Group: take any
Registry name: nareshdcr
Location: EastUS/JapanEast
Pricing Plan: Basic
And leave all rest values to default and finally click on Review+Create to
provision the container registry and this container registry will allow us to
build a docker container and host it.
Now come back to cloud shell and type the below command
az acr build --resource-group RGName --image demo/custom-image-
demo:v1 --registry containerRegistryName --file Dockerfile .
And with above command we can send the entire docker code, build it, and
store it on Azure docker container registry.
Now come back to Container Registry in Azure portal and click on Access
control IAM(left side)&gt;&gt;+Add&gt;&gt;Add role assignment&gt;&gt;privileged
administrator roles&gt;&gt;owner&gt;&gt;Next&gt;&gt;+Select members&gt;&gt;choose the user
which you have logged in with&gt;&gt;Select&gt;&gt;Next&gt;&gt;click on +Select roles and
principals&gt;&gt;click on configure in constrain roles box&gt;&gt;+Add role&gt;&gt;select
owner and contributor check
box&gt;&gt;select&gt;&gt;save&gt;&gt;save&gt;&gt;Next&gt;&gt;Review+Assign&gt;&gt;Refresh

Now click on repositories(in ACR left side)&gt;&gt;Refresh&gt;&gt; then will see our
container image as below
Demo/custom-image-demo
If we click on the container image above, then will find v1 as Version 1 that
we passed above.
Note: In container registry on left side click on access keys and Enable the
Admin User, if we don’t make it as enable then we cannot deploy the
private container instance by considering this container registry(very
important)

9
Now execute the below commands in a sequence of order in same cloud
shell window in Bash
az acr repository show-tags --name containerRegistryName --repository
repositoryName

az acr login -n containerRegistryName --expose-token

az acr repository list --name containerRegistryName --output table

az acr repository show --name containerRegistryName --repository
repositoryName --output table

Hence, here we have created custom docker image in private azure
container registry.

Docker is one of the most popular tools among all other container tools in the
industry while working with Azure Container repository we deal with Docker
CLI
Hosting custom image from our private container registry to WebApp(Azure
PAAS services):
Step1:
Click on Azure container registry that we have deployed&gt;&gt;repositories(left
side)&gt;&gt;click on repositories(Ex: demo/custom-image-demo)&gt;&gt;on V1 click on 3
dots extreme right(as shown in image below)&gt;&gt;click on Deploy to web app&gt;&gt;

10

Step2:
Give the site name&gt;&gt;Subscription&gt;&gt;Resource Group&gt;&gt;set app service
plan&gt;&gt;and finally click on create

11

Step3:
Wait for some time till the deployment gets completed&gt;&gt;go to app services
that we have deployed&gt;&gt;click on overview&gt;&gt;copy the url Default domain(as
shown in image below)&gt;&gt; and put it in a browser and finally here we can see
the custom image/app what we have implemented on top of Azure container
registry is finally provisioned on top of Azure App Services(which is Azure PASS
services)


In the world of docker container instance image is nothing but webapp/website

Demo1: Directly i am hosting my webapp on top of docker container instance
      Here in demo1  some other developers has build and deploy the image(website)
      direcly im using this image to host on top of docker container instances.

 Resource group:

- cick on resource group
- subscription- Azure subscription1
- resource group name- PLL-RG
- Region - Australia eat
- click on review+create

Container Instance
- click on Container Instance
- click on create
- subscription- Azure subscription1
- resource group name- PLL-RG
-container name-  plldci
-Region - austrial east
- sku- standard 
- image source- other registry
- image- ashfaque9x/my-html-website
- os type- linxu
- size-  1vcpu,1.5 gib 0 gpus
Networking
- dns name lable- paperlivelearingservices
- dns name lables scope resue tenant
Monitoring- default
advanced - default
- click onrewivew+create
- now got to plldci copy the ip address and open in the browser

DeMo2: Here in Demo2 also we are using the webapp/image direclty and hosting obn top of docker container
 instance but this time the image will take from microsoft container rregistry (MCR)

 Resource group:

- cick on resource group
- subscription- Azure subscription1
- resource group name- PLL-RG
- Region - Australia eat
- click on review+create

Container Instance
- click on Container Instance
- click on create
- subscription- Azure subscription1
- resource group name- PLL-RG
-container name-  pllmridci
-Region - austrial east
- image source- quick
- sku- standard 
- image -mcr.mcirosoft/azuredocs/aci-helloworld:latest
- os type- linxu
- size-  1vcpu,1.5 gib 0 gpus
Networking
- dns name lable- paperlivelearingservices
- dns name lables scope resue tenant
Monitoring- default
advanced - default
- click onrewivew+create
- now got to plldci copy the ip address and open in the browser


Demo3: Here we are customizing the webApp  on our own then will store this webapp in docker container
registry , will pull this webapp from docker container registry do docker container instance to host on top fo CI


container registry:

- go to container registry
- subscription
- resuorce group- PLL-RG
- registry name plldccr
- Domain name lable scop - unsecure
- Registry domain name- plldcr.azurecr.io
- click on create+review

- GO TO HOME
- click on cloudshell
- click on bash
- choose mount storage account
- click on subscriptoin
- choosse we will create a storage account for you
- git clone https://github.com/Azure-Samples/aci-helloworld.git
- ls
- cd aci-helloworld/
- code .
- it will ask to swtich ,click on ok
- change the code
-  az acr build --resource-group PLL-RG --image demo/custom-image-demo:v1 --registry plldcr --file Dockerfile .

Now 

- go to container registry
- cilck on access control  IAM
- click on add role assigment
- click on priviledged admiinstroator roles
- choose owner, lcik on next
- in Members, click on members
- choose the user which u have logged in with 
- clickn on next, click on select roles and principles or choose allow users to asign all roels (highly privileged)
-After the repository is deployed demo/custome-iumage-demo

- got to plldccr, search for access keys
- check the block for admin user
- go to plldccr, click on repositories

Container regitry name: plldcre
Repository  Name: demo/custom-image-demo

- az acr repository show-tags --name plldcr -- repository demo/custom-image-demo
- az acr login -n plldcr --expose-token
- az acr repository list --name plldcr --output table
- az acr repository show --name plldcr --repository demo/custom-image-demo --output table

Container Instance
- click on Container Instance
- click on create
- subscription- Azure subscription1
- resource group name- PLL-RG
-container name-  pllmycusotmizeddci
-Region - austrial east
- Image source- auzre container registry
- sku- azure container registry 
- registry -plldccr
- image -demo/custom-image-demo 
- image tag c1
- os type- linxu
- size-  1vcpu,1.5 gib 0 gpus
Networking
- dns name lable- paperlivelearingservices
- dns name lables scope resue tenant
Monitoring- default
advanced - default
- click onrewivew+create
- now got to plldci copy the ip address and open in the browser

4 Nov:
------

SqL DB's server:
-------------------
 We are learning how we can create , deploy and SqL DB's server, sql artifacts in  cloud conputing

SQL DB's SQL server>> cloud computing [ public cloud]
local lpatop >> On - prem [ private cloud ]
1 we should have at least 1 sql server to deploy sql databased
2. if we are not having and sql server then we cannot deploy sql DB
3. on top of 1 sql sever we can deploy multiple sql databases
4. if you want to connect cloud sqldb from your on prem then you have to enabled firewall ports
5. if you want to connect cloud sql db from your lpatop (on prem then compulsory  you hsouldh have  s
   sql server and  SSMD installed in your lpatops

- search for sql databases
- click on azure sql datbases
- click on create
- subscription - azure subscription1
- resrouce group - PLL-RG
- database name SQLDBinAzuer
- server- click on createnew-  sqlserverinazure1917
- location Japan est
- authentication method- choose use both sql and microsoft entra authentication 
- set microsoft entr aadmin- click on set admin- select the usser gareth@micorofot.com
- server admin login  Gareth
- password
- confirm password
- click on ok
- database name SQLDBinAzuer
- server- click on createnew-  sqlserverinazure1917 (japaest)
- want to user sql elastic pool - no
- workload enviroment- development
- compute + storage- click on configure database
- service tier- select standard
- DTUS- Choose 20
- Data max size GB- 40
- Backup storage redundancy - choose locally-redundant backup storage
- In networking 
- connectivity method- public endpoint
-  firewall rules
- allo azure services and resoiurce to access this server - yes
- add current client ip address- yes
- connection policy
- choose defulat uses redirect policy for all clent conneciton origination isidfe of azure
- In encrupted connections
- TLS version- tls1.2
- In security - default
-In additional setttins
- use exsting datat - non
- datbase collaton
- collation - sql latin1_General CPI1_CIA-AS- Defualt
- tags
-click on review +create

- Now got to sqlserverinazure1917
- In our personal windows click Microsoft sql server management studio
- Now give databasename  SQLDBinAzuer
           sql Server name sqlserverinazure1917
           Server admin login: Gareth
           password: Bangalore@123
- now expand the databases, you will willl see SQLDBinAzuer database
- now click on the links which provided in the documents, click on execute 




Azure key vault
-------------------
- go to home search for key vault.
- click on create
- subscription
- resource group name
- key vault name- PLLKV1515
- Region- japan east
- pricing tiert - standard
- days to retain deleted vaults - 60
- purge protection - disable
Acess configuration
- choose valut accesss policy
networking
- choose all networks
- revieww + create

- Now create a VM
- Subscription- azure subscription-1
- resource group - PLL-RG
- Virtual machine name- websever
- region - centrial idia
- availblity options- no infrastructure redundancy required
- security type- stadard
- image- windows
- admintstartor
  username webserver
  password Ameerpet@123
- public inbound ports- allow selected ports
- inbound rules - RDP(3389)
                  HTTPS(443)
                  HTTP(80)
- Click on review + create

- Now go to keyvault
- click on PLLKV1515
- click on generate/ input
- upload options- Manual
-  Name - websever
- secret value- Ameerpet@123
- set activation date- 
- set expiration data- 
- click on create

- Now go to keyvault
- click on PLLKV1515
- click on generate/ input
- upload options- Manual
-  Name - sqlserverinazure1917
- secret value- Bangalore@123
- set activation date- 
- set expiration data- 
- click on create

- search  for microsoft entra id, click on users
- user prinicipal nam- Madhav
- password
- click on review+create

- Now in PLLKV1515
- In access policies, i will give the user accesss to see the keys in the keysvault
- click on create
- select template- key & secret managemnet
- chose get list set in secret permissions
- In principal- search for Madhav and select
- click on review + create
- Now in PLLKV1515
- click on access control iam
- click on add role assigment
- click on privileged administrator access
- seelct contributor
- click on next
- In members, in Assign access to - choose user, group or service prinicpal, click on select
- click on review+create

Madhav user will login to azure portal with his credentials and then get the secret/password for webserver and sqwl server 
if you forgot credentails
- go to PLLKV1515
- click on secrets, click on show secret value of respective websever or database.

How we can schedule the backups of our Azure VMS:
Recovery services valut(RSV) this is an inbuild service we have in azure cloud computing( PAAS)
Mostly we use this RSV services to schedule and take the backups
RSV heps us to schedule the automated backups.
RSV helps us to take the full VM backup, but it will not hlpe us to taked customized backups.
RSV helps us to take the future disks backups.
RSV can take the backup only when the VM and RSV region is common.
RSV is region dependent, if the region 

6 nov
-----
In RSV how we can schedule the backup policies for our virtual machines

Recovery services valult(RSV) can take the backups of the VMS's only when  the regions are common
RSV region  and VM region are same then nly the backup is possible

right now my VM1 is having only c drive if at all after 2 months if i attached 2 more disks to my VM1 then the RSV will take
the backup of this 2 new disks also.

Now for vm2 backup we have to create another RSV in the australia east region  then only it is possible 
to schedule the VM2 backup

In RSV we can take file share backups also

RSV Backups:
---------------
creating VM1:

- Now create a VM
- Subscription- azure subscription-1
- resource group - PLL-RG-2
- Virtual machine name- vm1
- region - centrial idia
- availblity options- no infrastructure redundancy required
- security type- stadard
- image- windows 2025
- admintstartor
  username VM1
  password Bangalore@123
- public inbound ports- allow selected ports
- inbound rules - RDP(3389)
                  HTTPS(443)
                  HTTP(80)
- Click on review + create

- Now create a second VM2
- Subscription- azure subscription-1
- resource group - PLL-RG-2
- Virtual machine name- vm2
- region - australia east
- availblity options- no infrastructure redundancy required
- security type- stadard
- image- windows 2025
- admintstartor
  username VM2
  password Bangalore@123
- public inbound ports- allow selected ports
- inbound rules - RDP(3389)
                  HTTPS(443)
                  HTTP(80)
- Click on review + create


- Now go to recovery services vault
- click on create
-  subscription - azure subscripiton-1
- resource group- PLL-RG 2
- valt name-  pLL-RSV
- region - centrail india
- In redundancy- 
  backup storage redundancy- locally - redundanct
- encruption type- choose use microsoft managed key
- In networking, in connectivity method- choose alowpublic access from all networks
- click on rewview+ create
- Now go to pLL-RSV
- click on backup
- where is your wokload running- choose azure
- what do you want to backup- choose virtual machine
- In configure backup
- policy sub type- enhanced
                   Multiple backups per day
                   choose standard
                    once a day backup
- backup policy0 click on create new policy
- policy name- VM1BakPlcy
- frequency- daily time- 4:30 am, timezone- UTC
- Instant restore  - 2 days
- retention range- at 4:50 am  for 12 days
- retention of monthly backup point- week based
                                On - fourth, day- friday, at 4:30 amn for 2 months
- choose retention of yearly backup point
  choose week based
  in decmber on fourth, day -friday at 4:30 am for 2 years
- In virtual machines
- click on add 
- select VM1, choose include future disks as well
- click on enable backup

In RSV we can take file share backups also


Storage accounts:
- click on  storage accounts
- click on create
- subscription - Azure susbscription1
- Resource group name- PLL-RG-2
- storage account name- srcsa1118
- region central india
- Preferred storage type- Azure blob storage or azure data lake storage gne2
- Primary workload- backup and arhive
- Performance- standard
- Redudancy- locally redundant storage (LRS)
- In advanced
- choose require secure transfer for REST API operations
- choose allow enabling anonymous access on individual containers
- choose enable storage account key access
- choose default to microsft entra authoriazation in the azure protal
- minimum TLS version - version 1.2
- click on revew+create


- Now go to srcsa1118
- click on datastorage0 click on file share
- name- pllfs1
- click on nextbackup
- enable backup - choose
- receovery services valut - selext existing
- valt name0 PLL-RSV
- click on revew+create

- Now go to srcsa1118
- click on datastorage0 click on file share
- name- pllfs2
- click on review+create

or 

- now go to pLL-RSV
- click on protocted itemaas, click on backup items
- choose azure file share
- where is your wokload running- choose azure
- what do you want to backup- choose azure file shares
- In configure backup
- storage account- select srsca1118
- In File shares to backup
- click on add file share names
- 
- policy sub type- enhanced
                   Multiple backups per day
                  choose standard
                    once a day backup
- backup policy- click on create new policy
- policy name- VM1BakPlcy
- frequency- daily time- 4:30 am, timezone- UTC
- Instant restore  - 2 days
- retention range- at 4:50 am  for 12 days
- retention of monthly backup point- week based
                                On - fourth, day- friday, at 4:30 amn for 2 months
- choose retnetion of yearly backup point
  choose week based
  in decmber on fourth, day -friday at 4:30 am for 2 years
- click on enable backup


Azure Montoring:
--------------------
Im now performing some activities on top of VM1
stop the VM
start the VM
Restart the VM
upgrade the VM>>>- clini on avalitvlity + scale- click on size

All the above activities has been captured in azure monitor by default nothing has done from your end.

- Go to monitor in search bar
- you will see the logs of deallocate virtual amchine, restart , uipdate virutual macines

- click on create an alert rule
- select vm1 - click on apply
- click on see all signals
- select restart- click on apply
- click on next actions
- In details
- subscription - azure subsscription1
- resource group- PLL-RG2
- Region - global
- alert rule details
 alert rule name- VM1 restart
 alert rule description- get me an alert in the form of an Email whenever VM1 gets restarted
- click on  reveiw + create
- click on create
- Now in the Monitor | Alerts home page, click on alerts, click on alert rules
- you will see VM1 restart
- now click on vm1 restart
- click on edit
- click  create action group
- subscription - azure subsscription1
- resource group- PLL-RG2
- Region - global
- action group name - ActionGroup-VM1-restart
- display name- AGVM1Restart
- Notifications , notfication type- email/sms message
- email -
- country code -91
-phone no- 
- enable the common alert schema
- click on review+ create

- Now in the Monitor | metrics home page, click on metrics
- scop- vm1
- metric namespace - virtual machine host
- metric -percetage CPU
- Aggregation -avg
- you can save to dashboards




7 Nov:
------
What all the resources that we have created till now

Azure Active Directory(AAD
Servers
storage accounts
resrouc groups
load balancer
virtual networks ..etc

10 Members
1) Firstly will learn how we can onboard the users in microsoft entra ID
2) I made a login to azure portal with the same user  id
3) we have just onboarded the user , we have not provided any access to  any of the resources
   in azure cloud computing to the user theats why when the user logged in with his  credentials he is not able to see 
  any of the resources
4) will impletemnt identiy acces managemtn ( IAM) WITH ROLE BASED ACCESS control)
5) to upgrade roles
6) If i want to know one particular user is having what all access
7) If i want to know one particular user is having what all accesses
8) Bcoz we have not provided the access to the user at RG level  we have provided  access at VM level
9) for 1 vm it is fine you can easily give the acess what if there are 50 vms, 100 vms, 1500 vms
10)
There are 400 users  whom you have to give access to the weserver1

For some users 150 you need to give reader access
For some users 120  you need to tive contributor access
For some users 130  you need to give owner access


microsoft entra id:
--------------------

Creating User:
- serach for microsoft entra id
- click on users
- click on new users
-  user prinicpal name- 
- display name
- password
- account enabled
- In properties
- first name0
- lastname
- usertype
- authorization info
- Job infrormation
- contact ifnormation
- click on review + create

Creating resource VM:
- Now i will create on server
- Now create a VM
- Subscription- azure subscription-1
- resource group - PLL-RG-2
- Virtual machine name- Webserver1
- region - centrial idia
- availblity options- no infrastructure redundancy required
- security type- stadard
- image- windows 2025
- admintstartor
  username VM1
  password Bangalore@123
- public inbound ports- allow selected ports
- inbound rules - RDP(3389)
                  HTTPS(443)
                  HTTP(80)
- Click on review + create

Giving Access to the user by role based:
- Now click on  Webserver1
- In  IAM , clik on add role assignment
- search for reader, click on next
- In memebers- choose assign access to user group or service prinicpal
- click on select members
- sercch for the user 
- description- Provind reader access to Niranjan 
- clickn on review+create

- Now click on  Webserver1
- In  IAM , clik on add role assignment
- click on privileged administrator roles
- select contributor
- In memebers- choose assign access to user group or sercie prinicpal
- click on select members
- sercch for the user 
- Now the user can restart stop or updated the machine

If i want to know one particular user is having what all access

- if u go to micosoft entra id, click on users, click on user
- click on azure role assignemnts
- you can see if the user is having reader access or contributor access

If i want to know one particular user is having what all accesses
Bcoz we have not provided the access to the user at RG level  we have provided  access at VM level

- In Resource manager
- click on PLL-RG-2
- Click on access control IAM
- click on add role asssignment
- search for reader, click on next
- In memebers- choose assign access to user group or sercie prinicpal
- click on select members
- search for the user 
- description- Provind reader access to Niranjan 
- clickn on review+create

 for 1 vm it is fine you can easily give the acess what if there are 50 vms, 100 vms, 1500 vms

 40 vms belongs to PLL-RG
 50 VMS belogns to awamo-rg
 10 vm belongs to MyRG

if user forgot the password
- cick on  microsoft entra id
- click on users
- click on user
- click on reset password

There are 400 users  whom you have to give access to the weserver1

For some users 150 you need to give reader access
For some users 120  you need to tive contributor access
For some users 130  you need to give owner access

Im claiming that if i give the acccess to the  group then what all the user who are part of the group will get the access to azure resources automatically


- clikc on microsoft entra id
- click on groups
- click on new group
- group type- security
- group name0 PLL_Students_Reader_Access
- Group Description- creating this group to provider reader access to paaperlive learing students
- click on no owners slected- choose users
- click on no members selected- search  bhavana
- click on create
- In resourge Manager
- click on PLL-RG-2
- click on IAM, click on add role assignemnt
- click reader
- click on next
- In members 
  assign acces to users group or servide prinicpal
  click on seelct membewrs
- search for group name- PLL_Students_Reader_Access
- Descritpion - Provid reader access to the group DL
- click on review+assign



10 Nov
--------
Till now we were learning https://portal.azure.com

VM's
Vnets
LB's
TMP
SA's
RSV
Backups..etc

Azure Boards:
------------------

Now we are going to learn https://dev.azure.com>>

Azure Boards
Azure Repo's
Azure CI/CD pipelines


Different types of Boards available in Azure Devops/Azure Boards types:
Basically, there are four type of WORK ITEM PROCES will find while creating a new project in Azure Devops.
When we are creating a new project in Azure Devops then in Advance section will see there is a drop down for work item process and will see 4 values in the drop down those are 
(i)Basic>>	
(ii)Agile>>
(iii)Scrum>>
(iv)CMMI (Capability Maturity Model Integration).
The type of Boards depends on these work item process. Here each type of work item process (in drop down) will provide different types of work items and workflow.
These work items and workflow depends on the selection of work item process, if we choose the Basic one will have different type of work items and work flow, if we choose Agile (or) Scrum (or) CMMI then will get different type of work items and work flows for our Azure Devops projects.	


Work item: A work item is a unit(small or large) of work which has several characteristics, and it is a part of our product development. When we work on development of a product then we divide our tasks into small parts and that small parts or group of those parts we say it as a work item. Basically, each and every single type of work that we are doing in our project development can be consider as work item. Work item is an independent unit which can be track independently on our Azure Board


Characteristics of work item
Example of work item
Title 
Epic(an Epic is a work item)
Description
User story(user story is a work item)
Assigned To
Bug (bug is a work item)
Completed By…..etc.
Improvement…etc.


Work item in Azure Boards with Basic Process: when we work on Azure boards there are multiple types of boards, and all the boards depends on work item process which we have choose at the time of project creation.
What work items are available in Azure Boards when we work with Basic Process: 
There are three work items in Azure Boards with basic process. When we create a project with basic process then we have only 3 types of work items and i.e.: 

(i)Epic: An Epic is basically a kind of functionality or a kind of large work(ex: we have to implement login/sign-up/forgot password/…etc all these functionality in our application, so we can say Epic is a membership, basically all the things which are required in the membership will be a part of Epic)

(ii)Issue: Under this Epic we can create multiple type of issues and in Azure Boards with Basic process an issue is something that it may be a bug or a user story or an improvement…etc. all these are part of issue, and under this membership we can create multiple types of issues like login functionality /sign-up functionality /forgot password functionality…etc.

(iii)Task: Task is the smallest unit of work, firstly we have Epic then Issue and then Task and for each issue we can create multiple task (Ex of Task: under login functionality we can create multiple task like 
Task 1: creating table in the DB
Task 2: creating an API is another task
Task3: integration of API
Task4: Design of the login page…etc.)


Now we are going to learn https://dev.azure.com>>

- click on new organization
- Name your azure devops organiaztion - dev.azure.com/ PLL8PMBatch
- In PLL8PMBatch organization
- Project name- MyFirstProj
- Descriptioni- Creating this project for Paperlive Learning Students
- click on create project

- Now click on project -MyFirstProj
- you will see all the devops services in left column
- boards, backlogs, sprints, queries, delivery plans 
- cliick on Boards, You can see 3 cloumndsm ToDO, doing and done


- When you click on PLL8PMBatch organization
- click on new project, In advanced, in workitem process, you can see  3 work item process
  BASIC, CMMI, Scrum



- click on  MyFirstProj 
- click on project settings, clck on teams
- click on users
- click on add user
- In users you can provide the gmail id's
- Now come back to PLL8PMBatch organization, click on organization settings
- click on users
- add to projects- MyFirstProj
- click on add users

- choose send emails
- In MyFirstProj, click on project settings, click on teams 
- click on MyFirstProj Team, click on add, give the maild's and click on save

43:23
- go to boards
- click on boards
- in right top  you will have filter choose epic/issues ,choose epic , Now in ToDo ,click on new item
- type- applying for home loans, click on add top
- click on title of the work item-applying for home loans
- click on the user to assign
- select the user and click on save and close

- click on applying for home loans
- you can click ,select and drage from TO do to doing
- you can state, description, area,, iteration, reason, attach links, planning, priority, start date end date
  backlog, Todo,doing,done
-

- go to boards
- click on boards
- in right top  choose issues, click on new item
- type- login funcationaliy, click on add top
- click on title of the work item-login funcationaliy
- click on the user to assign
- select the user and click on save and close


- In each item,
  you will have state - todo, doing, done
  area- Myfirstproj
  iteration My FristProj\Sprint
  reason- Reactivated/started/completed
  description
  discussions
  Planning
   priority-2
   start date
   target date
  Related work  
    attach link


-If you want to create an issue which dependent on  epics , click on login funcationaliy mitem in doing list, click on 3 dots
and click on issue. for tasks which depende on issues, you can add tasks.

- click on 3 dots, clik on add task in the issue
- 
Sprints:
- click on the backlogs
- click on MyFirstProjTeam backlogs
- click on issues on top, click on new sprint on bottom right
- name, date, project
- if you want to move some issues to another sprint, click on move to iteration on right click of issue


11 Nov:
-----------

Azure Repos or Azure Repository:
---------------------------------------
1) Azure Repos or Azure Repository
2) We can create as many repos we want inside the Azure devops projects
3) Each Repo name should be unique
4) By default one Repo will get create in our Azure devops project and if you  
   create multiple repos depends upon the project requirement


Server repo:
    The repo which is in your devoops portal that is called server repo
Local repo:
     A simple foler


Prerequiste:
git software should be installed 
tortise git software should be installled
visual studion 2022 enterprise edition


RepoCreation:
- In the PLL8PMBatch organization, click on MyFirstProj
- click on repos, on myfirstproj repo , click on down arrow, click on new repository
- Repository type- GIt, repository name- PLLRepo1 ,click on create, you will see clone to your computer git URL

- open new folder  in the local repository
- /e/PLL8PMBatch/MyPracticeRepo
- git init
- dotnet new mvc ( to generate the project)
- git add .
- git commit -m "create new mv project"
- git push --set-upstream  PLLRepo1 url master


- create a new folder MyPracticeRepo1515 in the local repo
- git init
- git pull cloneurl of   PLLRepo1
- git add .
- git commit -m" added code in Homecontroller.cs file"
- git push --set-upstream PLLRepo1 url master
- refersh the page in the PLL8MBatch


For branch from server repo:
- click on master down arrow,
- name- PLL-B1
- based on maser
- you can also refer work items like, issues,taks,eppics but mostly you can ignore this
- click on create
- now in PLL-B1
- edit the changes
- Click on commit
- Now in master branch
- click on create pull request
- click on approve, click on complete,click on  merge
-  in merget type- merge( no fast forward)
   select complete associate  work items after merging
   select delete PLL-B1 after merging
          customize merge commit message
- click on complete merge



For file creation:
- click on 3 dots of repo on the folder
- click on create a file- HomeController1515
- In different branch-PLL-B2
- after commit
- create pull request
- merge 

To delete repo
- go to PLLRepo1 
- there you can delete rep

For branch from ocal repo:
- create a folder 
- git init
- git pull PLLRepo1 url
- git branch
- git branch india
- git checkout india
- git remote add origin url
- git push -u origin india
- 

- To delete a branch
- click on branches
- you will have  a option for delete

Rebase
Merge


Merge no fast farword commit:- it will keep the history of feature branch and add a new branch in the master

Master - a-b-c
feature a-b-c-d-e
master- a-b-c--f
          d e

squash commit :t will not keep the history of feature branch and add a new branch in the master
Master - a-b-c
feature a-b-c-d-e
master- a-b-c--f


Rebase and fastforward :
here will append all commits history of the feature branch in the  front of the master 
branch and her will not add extra dummy commit
Master - a-b-c-f-g
feature a-b-c-d-e
master- a-b-c--f-g-d-e


Semi-linear merge

Mix of rebase and normal merge


13th Nov
----------

Pipelines is one of the main services of Azure Devops projects
When we create an azure devops project then for sure will get this services
in pipelines we are implementing CI/CD



Azure Pipelines:
--------------------

If no permission you will get error as bellow
- In the PLL8PMBatch organization, click on MyFirstProj
- click on pipelines
- click create pipelines
- click on azure repogits
- click on PLLRepo1 
- click o ASP.NET
- Clikc on save and run
- fill the form from the url after getting error

If permission granted  your build  will get succeeded  as bellow

Creating build for MyRepoSimpleSignature Project:
---------------------------------------------
- In PLL8PMBatch organization
- Project name- PLL8PMBatch
- Descriptioni- Creating this project for Paperlive Learning Students
- click on create project
- In PLL8PMBatch project, click in repos, click on PLL8PMBatch, click on new repository
- repository name MyFirstRepo, click on create
- Now in the local repository ,
- open git bash termin in MyRepoSimpleSignature folder
- git init
- dotnet new mvc
- git add .
- git commit -m "created a new project"
- git push --set-upstream repourl master
- In PLL8PMBatch, click in pipelines,click on create pipeline,click on azure repos git, click on myfirstrepo, click on showmmore option
- click on APS.NET
- click on save and run
- Build will suceeded.
- if there is any changes, click on PLL8PMBatch project, click on MyFirstRepo,
- In the master, click on down arrow, click on new branch, branch name- PLL-B1
- click on create
- In the HomeController.cs you can make some changes, click on commit
- comment- updated the commit, click on commit
- click on create pull request, click on create, click on approve, click on complete
- click on complete merge
- Now come to your pipeline in PLL8PMBatch 
- you can see build status


Project:
Creating Build Pipeline for ASP.Net Web Applications using classic editor instead of Azure Repos Git:


WebAPPProject- mcv5 appproject
------------------------------------
- First will open the webapp project
- Will build the webapp project in our local laptop using VS 2022 Enterprise edit
- Once the build is succeeded then will run this project in our local laptop
- Will push this webapp project to our server repo
- Will do the build again in azure devops and once the build gets succeeded in Azure devops event then [ci]
- then finally will deply the webapp project to azure irtual macine CD


- Open VS2022
- Open the project, click on build, click on build solution, when build is suceed
- click on run

- In PLL8PMBatch, click in repos, click on PLL8PMBatch, click on new repository, name PLLWebAppProj
- Now in the local repository, click on new filder create-PLLWebAppProj, copy the source code of  mcv5
- open git bash termin in PLLWebAppProj,
- git init
- git add .
- git commit -m "pushing the project to Azure Devops repo"
- git push --set-upstream repourl master
- In PLL8PMBatch, click in pipelines, click on new pipeline ,click on use the classic editor
- repository -PLLWebAppProj, click on continue
- click on asp.net, click on apply, click on save and queue 
- click on save and run

- Now using IAAS will do CD and deploy the webapp

- Now create a VM
- Subscription- azure subscription-1
- resource group - PLL-RG-2
- Virtual machine name- PLL8PMBatch
- region - centrial idia
- availblity options- no infrastructure redundancy required
- security type- stadard
- image- windows 2025
- size 8gm 2 vcpus
- admintstartor
  username dev
  password Bangalore@123
- public inbound ports- allow selected ports
- inbound rules - RDP(3389)
                  HTTPS(443)
                  HTTP(80)
- Click on review + create

- now go to deployment groups in PLL8PMBatch
- deployment gropu nem Dev-DG
- Description - Creating this deployment group to deploy the webapp project in  Dev envirionments
- click on create
- check the box andclick on copy script to the clipboard

- now go into dev vm
- click on connect
- click on download RDP file
- give the credentials
- click on connect
- in the windows power shell
-  paste the script and enter ( to establish a connection between azure ciicd and vm)
-  now go back to PLL8PMBatch, click on deployment groups, you will see status as online


- click on release , click on new release pipeline
- click on add an artifact
- Project PLL8PMBatch
- source- PLL8PMBatch-ASP.NET-CI
- click on add
- click on stage
- if it is windows vm, search of iis website deployment
- click on apply
- stage2 name- dev, click on k
- click on 1 job 2 task link now in dev
- website name- PLLWebAppProj
- click on add bindings
- port 81
- click on ok
- deployment group- Dev-DG
- Timeout-15 m, job cancel time-15
- Artifact download- it will show PLL8MBatch ASP.NET-CI
- choose allow scripts to access the OAuth taken
-  click on ISS wb app manage  and enalbe IIS
- click on  ISS Web app deploy
- click o nsave
- comment- Designing of my release pipeline completed
- click on ok and click on create release on top
- click on create
- you will see sucessfull webpp on your VM




14th Nov:
-----------

Project:
----------
When we are deploying our webapp on top of Azure Vm;s then that is considered as IAAS
When we are deploying our webapp on top of app services then that is considered  as pAAS

Course-End Project-1:
======================
Implementing and automating the Azure Devops CI/CD Pipelines and a Project to host a ELearning web application for an Ed-tech company on modern cloud infrastructure for students, interns, university graduates and course completion students via Azure Devops CI/CD pipelines.

Project Agenda: Hosting ELearning Web App on Azure App Services [PAAS] using Azure Devops CI/CD Pipelines
===============

Description:
======================
PLL technologies is one of the reputed Ed-tech who are offering variety of different online/offline course for Students, Interns, University Alumni to offer variety of different courses for cutting edge technologies, The Ed-tech is based in the south Asian countries like (India, China, Singapore, Australia, Taiwan... Etc). The Ed-tech is helping students, interns and college alumni’s with different courses offerings as per their area of interest, the courses related to software’s development for cutting edge technologies (like: Cloud Computing, Devops, AI+ML, Cyber Security, IT Consulting, IT Infrastructure, Database Management, Azure Fundamentals, Azure Administration, Azure Devops, AWS cloud practitioners, AWS Solutions Architect…. etc).
AnilIT Ed-tech IT department treats its Web App as mission-critical and wants it to be available all the time, as in its absence, they will not be able to give a best impression and experience for their customers of their products, which can result in business loss.


Technical briefing of the Project:
===================================
This project will divide in multiple parts. i.e: Azure Repo’s, Build pipeline, Release pipeline & Azure App Services and in Build Pipeline if developers makes any change in Azure devops repository it will trigger the build pipeline automatically and pulls the code from its source repository and updates the code in Azure devops CI/CD pipelines.
Release Pipeline will be automatically triggered and it will pull the artifact from the build pipeline and this image it will deploy on Azure App Services and hence will able to see the complete Web Application is been hosted on top of Azure App Services(Web App…PAAS).


Architectural Diagram of the Project/Workflow:
===============================================

Azure Devops REAL-TIME-END-END-PROJECT
============================================           PipelineArtifact
                                                             | 
On-prem- devloper----------azure repo----------------- BuildPipeline---------------Release pipeline
                                                                                       |
                                                                                   AzureApp services
Pre-requisites to develop this project:
============================================

Azure Active Subscription in both the below portals
   (https://portal.azure.com & https://dev.azure.com )
Granted approval for parallelism from Microsoft for CI/CD pipelines.
Good Internet connection
Laptop with an internet connection. (any configuration)

In this project we are implementing:
============================================
-Resource Group(RG)
-Creation of an Organization & Private projects  in Azure devops
-Establishing service connection for App Services in Devops hosted in Azure portal
-Fetching the code from the source system and pushing it Azure Repos
-Verifying the CI/CD pipelines by making test commit
-Building CI/CD pipeline in devops project for Azure Web App
-Creating an App service in Azure portal
-Releasing of CI/CD pipeline to Azure App service deployment
-Access the application on web browser.
-Build/Release of the pipelines(CI/CD pipelines) starts again as part of an automation.
-Testing AnilIT technologies Ed-tech application in the browser
-Finally verify the application on the web browser.


Implementation Steps:
Note: Recommended to implement this project in Azure paid subscription.
Step 1: Create a repository (ELearningProj) in Azure Devops portal.
Step 2: Come to the path where we have stored our project in our local laptop(On-prem)
Step 3: Open git bash in the project repository
Step 4: Push the project to Azure repo’s by following the below git commands
git init
git add .
git commit -m "Pushing the ELearning Project to Azure Devops"
git push –-set-upstream repo_url master
Step 5: Build the project in Azure Devops portal by following the Step 6
Step 6: Click on Pipelines>>Create Pipeline>>Azure Repo’s Git>>choose the Repo ELearningProj>>Run>>wait for some 8-10 minutes till the build gets succeeded and Artifacts gets generated.


- In PLL8PMBatch, click in repos, click on PLL8PMBatch, click on new repository,name-ElearningProj,. click on create
- Now in the local repository, click on new filder create-ElearningProj,
- open git bash termin in ElearningProj,
- git init
- git add .
- git commit -m "Pushing Elearning Project to Azure Devops"
- git push --set-upstream repourl master
- In PLL8PMBatch, click in pipelines, click on Azure repo's git ,select the repo-ElearningProj,
- click on run

Step 7:  Come to Azure Portal[https://portal.azure.com/] and create Resource Group(RG)
Step 8: In Azure Portal and provision Web App [PAAS] under App Services by following the details
Subscription: 
Resource Group:
Name: ELearningProj
Publish: Code
Runtime stack: Node 22 LTS
Operating system: Linux
Region: Australia East(or any)
Linux Plan: ELearningProj-Plan
Pricing Plan: Free F1 (Shared infrastructure) [or any plan]
Click on Next: Database>>Next: Deployment>>Next: Networking>>Next: Monitor + secure>>Next: Tags>>Next : Review + create>>Create
Step 9: Wait for some time untill the App services gets deployed

- Create a resource group
- search for resource group
- click on create
- subscription - Azure subscription1
- Resource group name- PLL-RG
- Region - Australia East
- click on review + create

- In the home, click on app services
-  click on create web appp
- subscription - Azure subscription1
- Resource group name- PLL-RG
- name- ElearningProj
- publih - code 
- runtime stack Node 22 LTS
- Operation system- linux
- Region Austrial East
- Linux plan - click on create new- ElearningProj-Plan
- Priciing Plan - Free f1
- Database - defualt
- Deployment - defualt
- Networking - defualt
- Monitor+secure - defualt
- click on revew+create
- now go to ElearningProj, You can see in the defual domain url in browser, yoyu will see default webape


Step 10: If we access the web App in browser from Azure portal then will see the default web page on our web App…our plan is to host the Ed-tech web application on our web App
Step 11: Come to Microsoft Entra ID(in Azure portal)>>App registrations >>+New registration>>Name: ServiceConnectionToAzureDevopsProject>>Register>>click on Add a certificate or secret(right side for client credentials)>>+New client secret>>Description: AzureDevopsConnect>>Add>>immediately copy the value and paste it in a separate notepad(as this value will not be visible again if we change the window)
Step 12: Goto Subscription>>Access control (IAM)>>Check access>>in search type meher.tech(here search the azure subscription mail id with which we are having an azure account)>>Click on the appeared mail id>>and ensure you should be having the below accesses(in this mainly contributor access is important) 
	
Step 13: goto subscription>>Access control(IAM)>>Add>>Add role assignment>>Privileged administrator role>>Contributor>>+Select member>>search ServiceConnectionToAzureDevopsProject(this application we have registered in Microsoft EntraID)>>click on it>>Select>>Next>>Review+Assign>>wait for some time refresh the Azure portal to update the access.
Step 14: Come to Azure Devops>>click on the organization where your project is present (ex: MyProject9876)>>ElearningProj>>Project settings>>Service connections>>Create a service connection>>Azure resource manager>>Next>>For Identity type click the drop down and choose App registration or managed identity(manual)>>For credential click the drop down and select secret followed with other details as shown below
	Identity type: App registration or managed identity(manual)
	Credential: secret
	Subscription ID: Pass the subscription ID accordingly
	Subscription Name: pass the subscription name accordingly
	Application(client)ID: Get this from EntraID where we have register Application as ServiceConnectionToAzureDevopsProject
Directory(tenant) ID: Get this from EntraID where we have register Application as ServiceConnectionToAzureDevopsProject
Client Secret: Get this from Notepad that we have saved and click on verify and this should get succeeded as shown below
	
	Service Connection Name: ConnectingToELearningProj
	Check the box for Grant access permission to all pipelines
	Finally click on Verify and save


- In ElearningProj, click on defualt domain , you will see deafult web page
- Now go to microsoft intra id, click on app registrations
- click on new registrations
- Name- ServiceConnectionToAzureDevopsProject
- click on register 
- Now in ServiceConnectionToAzureDevopsProject, 
  In client credentialsclick on add certificate or secret
- click on new client secret
- description - AzureDevopsConnect
- click on add
- copy the secret id and paste it inyour notepadd


- click on azure subscription 1 , In Access control IAM, click on check access, give your id to check if you have contributor access

- click on  IAM, CLICK ON ADD role assigment
- click on privileged adminitrator tools, serach for contributor, click on next
- In members, In Assign access to , choose user group or servcie prinicpal
- Members - click on select members
- search for ServiceConnectionToAzureDevopsProject, click on select
- click on next
- clik on rewview+assign


- now come back to azure devops
- click on PLL8PMBatch,click on project setting
- In pipeline, click on service connections
- choose azure resrouce manager
- click on next
- identity type- choose app registraction or managed idently
- credential- secret
- Environment- Azure cloud
- subscription id ( click on azure subscription 1 and copy the subscription ID)
- subscription name- Azure subscription 1
- application client id( proviced from entra id, path- intra id, app reegistrations, click on ServiceConnectionToAzureDevopsProject ,copy the application ID)
- directory client id ( proviced from entra id, path- intra id, app reegistrations, click on ServiceConnectionToAzureDevopsProject,copy the directory ID)
- client secret (PASTe the secret which u have save in nodepad)
- click on verify
- select greant permission to all the piplines
- click on verify and save



Step 15: Click on Release (under pipeline)>>click on New pipeline>>close the window right side>>Add an artifact>>For 
Source (build pipeline): Here select the latest build carefully and choose the latest   build of this project only>>click Add finally.
Step 16: Click on +Add a stage>>Select Azure App Service deployment >>click on Apply>>Stage name: Dev(or any)>>close the window.
Step 17: click on 1 job, 1 task>>click for Azure subscription drop down
	Azure Subscription: ConnectingToELearningProj
	App type: Web App on Linux
	App service name: ELearningProj
Step 18: click on Deploy Azure App Service(as shown in image below)>>move the cursor towards right>>scroll down a little>>click on 3 dots of Package or folder(as shown in image below)>>a window open(as shown in image below)>>click on  ELearningProj(Build) folder>>Ok>>finally click on Save>>Ok

Step 19: Click on Pipeline(shown below)>>click on continuous deployment trigger>>Enable the option to Create a release everytime a new build is available>>close the window @ the top>>click on Save>>Ok

Step 19: come to our local laptop>>go to the path where we have saved  the project(Ex: E:\ELearning-CourseEndProj\ELearning-CourseEndProj)>>right click on server.js file>>Edit in Notepad>>come to Azure portal>>goto App services>>ELearningProj>>copy the default domain URL(as shown in image)>>Paste it in a server.js file prefix with https://(as shown in image below)>>click on File(at the top)>>Save

Step 20: Come to the folder in our local laptop where we have save the project(Ex: E:\ELearning-CourseEndProj\ELearning-CourseEndProj)>>Open git bash>>execute the below commands to push the latest code changes we have done in the server.js file.
Git init
Git add .
Git commit -m “modified code in the file”
Git push –-set-upstream RepoURL master
Step 21: The Build will get start here automatically as it is the nature of devops(if not then we can also start the build manually after the code changes by clicking on Run pipeline>>Run)>>wait for some 8-10 minutes for the build to be completed.
Step 22:  click on Releases (under pipelines)>>Edit>>Create release>>create(to deploy the latest build(CI) to release(CD) again)
Step 23: Come to Azure portal>>App services>>Development tools(left side under Web App)>>Advanced Tools>>Go>>choose the right subscription in which we have deployed our Web App>>click on Bash>>type below commands
ls>>hit Enter [with this command listing the No of folders and files]
cd site>>hit Enter [with this command getting inside the site directory]
ls>>hit Enter [with this command listing the No of folders and files]
cd wwwroot>>hit enter [with this command getting inside the wwwroot directory]
ls>>hit Enter [with this command listing the No of folders and files]
cd drop>>hit Enter [with this command getting inside the drop directory]
ls>>hit Enter [with this command listing the No of folders and files]
mv /home/site/wwwroot/drop/* /home/site/wwwroot>>hit Enter 
ls>>hit Enter [with this command listing the No of folders and files]
cd ..>>hit Enter [here coming out of drop folder]
ls>> hit enter [with this command listing the No of folders and files]
rm -rf drop>>hit Enter  [here with this command we are deleting drop folder]
ls>>hit Enter  [here we are verifying the drop folder is been deleted now]

Screen shot below:


Step 24: Come to Azure portal>>Web App>>Restart the web App>>refresh the browser multiple times>>wait for some time>>click on Browse>>and here will see our web application is been hosted on top of Azure App Services.
Step 25: Browse the website in the URL and we can navigate here to different pages of the website as per the need of our requirements for browsing.

Hence, we have developed the project by fetching the code from local repo by creating a service connection in Azure Devops and hosted the project on top of Azure PAAS services.


- now click on releases in PLL8PMBatch
- click on add an aritifact
- source ElearningProj
- click on add
- click on stage
- select azure app service deployment
- click on apply
- stage name- Dev
- click on 1 job , 1 task
- click on tasks, in azure subscriptions- select connectiontoElearningProject)
- app type web app on linux
- app service name- ElearningProj, click on save
- click on deply azure app service
- package or folder click on 3 dots, 
- click on elearning proj build, click ok
- click on save on top and click on ok
- click on pipeline
- click on continous deployemt trigger(In artifacts looks lik thunder button)
- enalbed the option for creates a release every time a new build available
- click on save , click ok
- comment- - Desingin the release piplienes, click onk
- come to our local project drive path, 
- make some chanbes in server.js
- git init
- git add .
- git commit -m "Applied the webapp URL form Azure as PAAS services"
- git push --set-upstream Elearningrepo url master

- now go to releases, click on edit
- click on create releases
- click on create

- Now go to appservices
- click on  ElearningProj
- click on Development tools
- click on advanced tools, click on go
- sign in
- click on bash in the Azure appservices
- cd site
- cd wwwroot
- cd drop
- ls
- mv /home/site/wwwroot/drop/* /home/site/wwwroot
- ls
- cd ...
- rm -rf drop
- ls
- now go to ElearningProj in appservices, clkck on restart
- now copy the defulat domain You will see the web application.






